{
  "algo": "PPO-MAML",
  "meta_batch_size": 20,
  "hidden_sizes": [
    64,
    64
  ],
  "rollouts_per_meta_task": 40,
  "parallel": true,
  "max_path_length":100,
  "discount": 0.99,
  "gae_lambda": 1.0,
  "normalize_adv": true,
  "positive_adv": false,
  "inner_lr": 0.1,
  "num_inner_grad_steps": 1,
  "learning_rate": 1e-3,
  "num_ppo_steps": 5,
  "num_minibatches": 1,
  "clip_eps": 0.5,
  "clip_outer": true,
  "target_outer_step": 0,
  "target_inner_step": 2e-2,
  "init_outer_kl_penalty": 0,
  "init_inner_kl_penalty": 1e-3,
  "adaptive_outer_kl_penalty": false,
  "adaptive_inner_kl_penalty": false,
  "anneal_factor": 1.0,
  "entropy_bonus": 0.0,
  "n_itr": 300
}