import numpy as np
from meta_mb.utils.filters import Filter

from meta_mb.utils import Serializable
from collections import OrderedDict


class NpPolicy(Serializable):
    """
    A container for storing the current pre and post update policies
    Also provides functions for executing and updating policy parameters

    Note:
        the preupdate policy is stored as tf.Variables, while the postupdate
        policy is stored in numpy arrays and executed through tf.placeholders

    Args:
        obs_dim (int): dimensionality of the observation space -> specifies the input size of the policy
        action_dim (int): dimensionality of the action space -> specifies the output size of the policy
        name (str) : Name used for scoping variables in policy
        hidden_sizes (tuple) : size of hidden layers of network
        learn_std (bool) : whether to learn variance of network output
        hidden_nonlinearity (Operation) : nonlinearity used between hidden layers of network
        output_nonlinearity (Operation) : nonlinearity used after the final layer of network
    """
    def __init__(self,
                 obs_dim,
                 action_dim,
                 name='np_policy',
                 **kwargs
                 ):
        Serializable.quick_init(self, locals())

        self.obs_dim = obs_dim
        self.action_dim = action_dim
        self.name = name

        self._dist = None
        self.policy_params = None
        self.policy_params_batch = None
        self._num_deltas = None
        self.obs_filters = [Filter((self.obs_dim,))]

    def get_action(self, observation):
        """
        Runs a single observation through the specified policy

        Args:
            observation (array) : single observation

        Returns:
            (array) : array of arrays of actions for each env
        """
        raise NotImplementedError

    def get_actions(self, observations):
        """
        Runs each set of observations through each task specific policy

        Args:
            observations (array) : array of arrays of observations generated by each task and env

        Returns:
            (tuple) : array of arrays of actions for each env (meta_batch_size) x (batch_size) x (action_dim)
                      and array of arrays of agent_info dicts
        """
        raise NotImplementedError

    def get_deltas(self, num_deltas):
        deltas = OrderedDict()
        for k, v in self.policy_params.items():
            deltas[k] = np.random.randn(num_deltas, *v.shape)
        return deltas

    def set_deltas(self, deltas, delta_std=1., symmetrical=True):
        self.policy_params_batch = OrderedDict()
        for k, v in self.policy_params.items():
            if symmetrical:
                delta = np.concatenate([deltas[k], -deltas[k]])
            else:
                delta = deltas[k]
            self.policy_params_batch[k] = np.expand_dims(v, axis=0) + delta * delta_std
        self._num_deltas = len(delta)

    def reset(self, dones=None):
        pass

    def log_diagnostics(self, paths):
        """
        Log extra information per iteration based on the collected paths
        """
        pass

    """ --- methods for serialization --- """

    def get_params(self):
        """
        Get the tf.Variables representing the trainable weights of the network (symbolic)

        Returns:
            (dict) : a dict of all trainable Variables
        """
        return self.policy_params

    def get_param_values(self):
        """
        Gets a list of all the current weights in the network (in original code it is flattened, why?)

        Returns:
            (list) : list of values for parameters
        """
        return list(self.policy_params.values())

    def set_params(self, policy_params):
        """
        Sets the parameters for the graph

        Args:
            policy_params (dict): of variable names and corresponding parameter values
        """
        assert all([k1 == k2 for k1, k2 in zip(self.get_params().keys(), policy_params.keys())]), \
            "parameter keys must match with variable"

        for k, v in policy_params.items():
            self.policy_params[k] = v

    def get_stats_filter(self):
        return [obs_filter.get_params() for obs_filter in self.obs_filters]

    def stats_increment(self):
        for obs_filter in self.obs_filters:
            obs_filter.stats_increment()

    def __getstate__(self):
        state = {
            'init_args': Serializable.__getstate__(self),
            'network_params': self.get_params(),
            'filter': [obs_filter.get_params() for obs_filter in self.obs_filters],
        }
        return state

    def __setstate__(self, state):
        Serializable.__setstate__(self, state['init_args'])
        self.set_params(state['network_params'])
        [obs_filter.set_params(params) for obs_filter, params in zip(self.obs_filters, state['filter'])]
