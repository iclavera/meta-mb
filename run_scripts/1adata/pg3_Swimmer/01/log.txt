Logging to /Users/sarahyoung/cs287/hw5_release_v2 2/ppo/run_scripts/data/pg3_Swimmer/01

 ---------------- Iteration 0 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 0           |
| ItrTime                 | 172         |
| LossAfter               | -1.4532825  |
| LossBefore              | 0.021803858 |
| Time                    | 172         |
| Time-Optimization       | 6.59        |
| Time-SampleProc         | 0.0411      |
| Time-Sampling           | 165         |
| n_timesteps             | 10000       |
| train-AverageDiscoun... | 16.3        |
| train-AverageReturn     | 10.1        |
| train-EnvExecTime       | 4.33        |
| train-MaxReturn         | 27.1        |
| train-MinReturn         | -5.56       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 160         |
| train-StdReturn         | 8.04        |
-----------------------------------------

 ---------------- Iteration 1 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 1            |
| ItrTime                 | 188          |
| LossAfter               | -5.601584    |
| LossBefore              | 0.0067927004 |
| Time                    | 360          |
| Time-Optimization       | 3.55         |
| Time-SampleProc         | 0.0215       |
| Time-Sampling           | 184          |
| n_timesteps             | 20000        |
| train-AverageDiscoun... | 40.8         |
| train-AverageReturn     | 24.8         |
| train-EnvExecTime       | 4.29         |
| train-MaxReturn         | 31.5         |
| train-MinReturn         | 0.217        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 179          |
| train-StdReturn         | 4.15         |
------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 2            |
| ItrTime                 | 173          |
| LossAfter               | -5.10633     |
| LossBefore              | 0.0071459655 |
| Time                    | 532          |
| Time-Optimization       | 3.46         |
| Time-SampleProc         | 0.0328       |
| Time-Sampling           | 169          |
| n_timesteps             | 30000        |
| train-AverageDiscoun... | 39.6         |
| train-AverageReturn     | 25.8         |
| train-EnvExecTime       | 4.05         |
| train-MaxReturn         | 29.7         |
| train-MinReturn         | 8.7          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 165          |
| train-StdReturn         | 2.75         |
------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 3            |
| ItrTime                 | 177          |
| LossAfter               | -3.3699      |
| LossBefore              | 0.0046164338 |
| Time                    | 709          |
| Time-Optimization       | 2.88         |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 174          |
| n_timesteps             | 40000        |
| train-AverageDiscoun... | 37.6         |
| train-AverageReturn     | 26.3         |
| train-EnvExecTime       | 4.1          |
| train-MaxReturn         | 29.7         |
| train-MinReturn         | 19.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 169          |
| train-StdReturn         | 1.86         |
------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 4           |
| ItrTime                 | 183         |
| LossAfter               | -1.8583944  |
| LossBefore              | -0.01204717 |
| Time                    | 892         |
| Time-Optimization       | 3.99        |
| Time-SampleProc         | 0.019       |
| Time-Sampling           | 179         |
| n_timesteps             | 50000       |
| train-AverageDiscoun... | 37.1        |
| train-AverageReturn     | 26.6        |
| train-EnvExecTime       | 4.11        |
| train-MaxReturn         | 29.3        |
| train-MinReturn         | 20.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 175         |
| train-StdReturn         | 1.75        |
-----------------------------------------

 ---------------- Iteration 5 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 5            |
| ItrTime                 | 174          |
| LossAfter               | -1.0600858   |
| LossBefore              | 0.0004452606 |
| Time                    | 1.07e+03     |
| Time-Optimization       | 2.88         |
| Time-SampleProc         | 0.101        |
| Time-Sampling           | 171          |
| n_timesteps             | 60000        |
| train-AverageDiscoun... | 35.9         |
| train-AverageReturn     | 26.1         |
| train-EnvExecTime       | 4.08         |
| train-MaxReturn         | 31.9         |
| train-MinReturn         | 9.37         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 166          |
| train-StdReturn         | 3.4          |
------------------------------------------

 ---------------- Iteration 6 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 6            |
| ItrTime                 | 173          |
| LossAfter               | -0.742713    |
| LossBefore              | 0.0075212996 |
| Time                    | 1.24e+03     |
| Time-Optimization       | 3.19         |
| Time-SampleProc         | 0.0196       |
| Time-Sampling           | 170          |
| n_timesteps             | 70000        |
| train-AverageDiscoun... | 36.4         |
| train-AverageReturn     | 26.6         |
| train-EnvExecTime       | 4.12         |
| train-MaxReturn         | 29.9         |
| train-MinReturn         | 21.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 166          |
| train-StdReturn         | 1.72         |
------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 7             |
| ItrTime                 | 180           |
| LossAfter               | -0.6164004    |
| LossBefore              | -0.0017264229 |
| Time                    | 1.42e+03      |
| Time-Optimization       | 3.68          |
| Time-SampleProc         | 0.02          |
| Time-Sampling           | 176           |
| n_timesteps             | 80000         |
| train-AverageDiscoun... | 36.4          |
| train-AverageReturn     | 26.7          |
| train-EnvExecTime       | 4.1           |
| train-MaxReturn         | 31.6          |
| train-MinReturn         | 15.4          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 172           |
| train-StdReturn         | 2.04          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 8             |
| ItrTime                 | 171           |
| LossAfter               | -0.5139008    |
| LossBefore              | -0.0063182204 |
| Time                    | 1.59e+03      |
| Time-Optimization       | 3.06          |
| Time-SampleProc         | 0.0686        |
| Time-Sampling           | 168           |
| n_timesteps             | 90000         |
| train-AverageDiscoun... | 36            |
| train-AverageReturn     | 26.6          |
| train-EnvExecTime       | 4.17          |
| train-MaxReturn         | 30.6          |
| train-MinReturn         | 10.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 164           |
| train-StdReturn         | 2.68          |
-------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 9             |
| ItrTime                 | 166           |
| LossAfter               | -0.45915958   |
| LossBefore              | 0.00034726333 |
| Time                    | 1.76e+03      |
| Time-Optimization       | 3.59          |
| Time-SampleProc         | 0.0199        |
| Time-Sampling           | 163           |
| n_timesteps             | 100000        |
| train-AverageDiscoun... | 36.5          |
| train-AverageReturn     | 27            |
| train-EnvExecTime       | 4.17          |
| train-MaxReturn         | 29.8          |
| train-MinReturn         | 19.6          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 158           |
| train-StdReturn         | 1.57          |
-------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 10            |
| ItrTime                 | 178           |
| LossAfter               | -0.43321934   |
| LossBefore              | -0.0039004767 |
| Time                    | 1.93e+03      |
| Time-Optimization       | 3.34          |
| Time-SampleProc         | 0.0207        |
| Time-Sampling           | 174           |
| n_timesteps             | 110000        |
| train-AverageDiscoun... | 36.7          |
| train-AverageReturn     | 27.1          |
| train-EnvExecTime       | 4.16          |
| train-MaxReturn         | 30.2          |
| train-MinReturn         | 18.5          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 170           |
| train-StdReturn         | 1.55          |
-------------------------------------------

 ---------------- Iteration 11 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 11          |
| ItrTime                 | 176         |
| LossAfter               | -0.40161878 |
| LossBefore              | 0.011378165 |
| Time                    | 2.11e+03    |
| Time-Optimization       | 2.95        |
| Time-SampleProc         | 0.0283      |
| Time-Sampling           | 173         |
| n_timesteps             | 120000      |
| train-AverageDiscoun... | 36.6        |
| train-AverageReturn     | 26.8        |
| train-EnvExecTime       | 4.12        |
| train-MaxReturn         | 31          |
| train-MinReturn         | 19.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 168         |
| train-StdReturn         | 1.8         |
-----------------------------------------

 ---------------- Iteration 12 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 12            |
| ItrTime                 | 177           |
| LossAfter               | -0.3866571    |
| LossBefore              | -0.0028928246 |
| Time                    | 2.29e+03      |
| Time-Optimization       | 4.19          |
| Time-SampleProc         | 0.0405        |
| Time-Sampling           | 173           |
| n_timesteps             | 130000        |
| train-AverageDiscoun... | 36.7          |
| train-AverageReturn     | 27.1          |
| train-EnvExecTime       | 4.13          |
| train-MaxReturn         | 30.5          |
| train-MinReturn         | 23.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 168           |
| train-StdReturn         | 1.43          |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 13           |
| ItrTime                 | 238          |
| LossAfter               | -0.3433516   |
| LossBefore              | 0.0010408661 |
| Time                    | 2.53e+03     |
| Time-Optimization       | 5.82         |
| Time-SampleProc         | 0.068        |
| Time-Sampling           | 232          |
| n_timesteps             | 140000       |
| train-AverageDiscoun... | 37.1         |
| train-AverageReturn     | 27.4         |
| train-EnvExecTime       | 5.49         |
| train-MaxReturn         | 31.9         |
| train-MinReturn         | 25.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 226          |
| train-StdReturn         | 1.45         |
------------------------------------------

 ---------------- Iteration 14 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 14           |
| ItrTime                 | 256          |
| LossAfter               | -0.3260977   |
| LossBefore              | 0.0083232215 |
| Time                    | 2.78e+03     |
| Time-Optimization       | 3.89         |
| Time-SampleProc         | 0.0744       |
| Time-Sampling           | 252          |
| n_timesteps             | 150000       |
| train-AverageDiscoun... | 36.6         |
| train-AverageReturn     | 27.1         |
| train-EnvExecTime       | 4.9          |
| train-MaxReturn         | 29.6         |
| train-MinReturn         | 22.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 246          |
| train-StdReturn         | 1.35         |
------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 15            |
| ItrTime                 | 294           |
| LossAfter               | -0.31850782   |
| LossBefore              | -0.0022351441 |
| Time                    | 3.08e+03      |
| Time-Optimization       | 7.53          |
| Time-SampleProc         | 0.0466        |
| Time-Sampling           | 287           |
| n_timesteps             | 160000        |
| train-AverageDiscoun... | 36.5          |
| train-AverageReturn     | 26.8          |
| train-EnvExecTime       | 4.76          |
| train-MaxReturn         | 30.4          |
| train-MinReturn         | 10.2          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 281           |
| train-StdReturn         | 2.32          |
-------------------------------------------

 ---------------- Iteration 16 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 16          |
| ItrTime                 | 398         |
| LossAfter               | -0.28810993 |
| LossBefore              | 0.00680327  |
| Time                    | 3.47e+03    |
| Time-Optimization       | 7.54        |
| Time-SampleProc         | 0.0792      |
| Time-Sampling           | 390         |
| n_timesteps             | 170000      |
| train-AverageDiscoun... | 36.7        |
| train-AverageReturn     | 27.1        |
| train-EnvExecTime       | 5.22        |
| train-MaxReturn         | 30.5        |
| train-MinReturn         | 22.5        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 384         |
| train-StdReturn         | 1.21        |
-----------------------------------------

 ---------------- Iteration 17 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 17            |
| ItrTime                 | 250           |
| LossAfter               | -0.2585291    |
| LossBefore              | -0.0029046875 |
| Time                    | 3.72e+03      |
| Time-Optimization       | 4.08          |
| Time-SampleProc         | 0.0242        |
| Time-Sampling           | 246           |
| n_timesteps             | 180000        |
| train-AverageDiscoun... | 36.8          |
| train-AverageReturn     | 27.1          |
| train-EnvExecTime       | 4.74          |
| train-MaxReturn         | 29.4          |
| train-MinReturn         | 21.3          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 241           |
| train-StdReturn         | 1.48          |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 18            |
| ItrTime                 | 223           |
| LossAfter               | -0.24516988   |
| LossBefore              | -0.0017049286 |
| Time                    | 3.95e+03      |
| Time-Optimization       | 4.08          |
| Time-SampleProc         | 0.026         |
| Time-Sampling           | 219           |
| n_timesteps             | 190000        |
| train-AverageDiscoun... | 36.7          |
| train-AverageReturn     | 27.1          |
| train-EnvExecTime       | 4.69          |
| train-MaxReturn         | 30.1          |
| train-MinReturn         | 23.8          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 214           |
| train-StdReturn         | 1.31          |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 19           |
| ItrTime                 | 196          |
| LossAfter               | -0.23635645  |
| LossBefore              | 0.0013536068 |
| Time                    | 4.14e+03     |
| Time-Optimization       | 3.8          |
| Time-SampleProc         | 0.022        |
| Time-Sampling           | 192          |
| n_timesteps             | 200000       |
| train-AverageDiscoun... | 36.9         |
| train-AverageReturn     | 27.2         |
| train-EnvExecTime       | 4.32         |
| train-MaxReturn         | 30.2         |
| train-MinReturn         | 23           |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 187          |
| train-StdReturn         | 1.42         |
------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 20           |
| ItrTime                 | 246          |
| LossAfter               | -0.2324159   |
| LossBefore              | 0.0028287338 |
| Time                    | 4.39e+03     |
| Time-Optimization       | 4.11         |
| Time-SampleProc         | 0.0423       |
| Time-Sampling           | 242          |
| n_timesteps             | 210000       |
| train-AverageDiscoun... | 36.7         |
| train-AverageReturn     | 27           |
| train-EnvExecTime       | 4.88         |
| train-MaxReturn         | 29.9         |
| train-MinReturn         | 21.8         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 236          |
| train-StdReturn         | 1.37         |
------------------------------------------

 ---------------- Iteration 21 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 21          |
| ItrTime                 | 321         |
| LossAfter               | -0.20600678 |
| LossBefore              | 0.020338444 |
| Time                    | 4.71e+03    |
| Time-Optimization       | 4.29        |
| Time-SampleProc         | 0.0465      |
| Time-Sampling           | 316         |
| n_timesteps             | 220000      |
| train-AverageDiscoun... | 36.4        |
| train-AverageReturn     | 26.9        |
| train-EnvExecTime       | 4.51        |
| train-MaxReturn         | 29.6        |
| train-MinReturn         | 12.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 311         |
| train-StdReturn         | 2.22        |
-----------------------------------------

 ---------------- Iteration 22 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 22          |
| ItrTime                 | 245         |
| LossAfter               | -0.23839425 |
| LossBefore              | 0.005337629 |
| Time                    | 4.95e+03    |
| Time-Optimization       | 3.16        |
| Time-SampleProc         | 0.0388      |
| Time-Sampling           | 241         |
| n_timesteps             | 230000      |
| train-AverageDiscoun... | 36.8        |
| train-AverageReturn     | 27          |
| train-EnvExecTime       | 4.18        |
| train-MaxReturn         | 30.9        |
| train-MinReturn         | 21.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 237         |
| train-StdReturn         | 1.46        |
-----------------------------------------

 ---------------- Iteration 23 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 23          |
| ItrTime                 | 185         |
| LossAfter               | -0.23950998 |
| LossBefore              | 0.007362793 |
| Time                    | 5.14e+03    |
| Time-Optimization       | 3.71        |
| Time-SampleProc         | 0.0203      |
| Time-Sampling           | 181         |
| n_timesteps             | 240000      |
| train-AverageDiscoun... | 37          |
| train-AverageReturn     | 27.3        |
| train-EnvExecTime       | 3.97        |
| train-MaxReturn         | 30.6        |
| train-MinReturn         | 22.2        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 177         |
| train-StdReturn         | 1.35        |
-----------------------------------------

 ---------------- Iteration 24 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 24           |
| ItrTime                 | 239          |
| LossAfter               | -0.24865513  |
| LossBefore              | 0.0028451965 |
| Time                    | 5.38e+03     |
| Time-Optimization       | 5.96         |
| Time-SampleProc         | 0.166        |
| Time-Sampling           | 233          |
| n_timesteps             | 250000       |
| train-AverageDiscoun... | 36.8         |
| train-AverageReturn     | 27.1         |
| train-EnvExecTime       | 5.21         |
| train-MaxReturn         | 30.8         |
| train-MinReturn         | 19.3         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 227          |
| train-StdReturn         | 1.66         |
------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 25           |
| ItrTime                 | 331          |
| LossAfter               | -0.2497941   |
| LossBefore              | 0.0044949013 |
| Time                    | 5.71e+03     |
| Time-Optimization       | 11.3         |
| Time-SampleProc         | 0.0541       |
| Time-Sampling           | 320          |
| n_timesteps             | 260000       |
| train-AverageDiscoun... | 37.2         |
| train-AverageReturn     | 27.5         |
| train-EnvExecTime       | 5.01         |
| train-MaxReturn         | 31.2         |
| train-MinReturn         | 24.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 314          |
| train-StdReturn         | 1.29         |
------------------------------------------

 ---------------- Iteration 26 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 26           |
| ItrTime                 | 474          |
| LossAfter               | -0.2638589   |
| LossBefore              | -0.003888022 |
| Time                    | 6.18e+03     |
| Time-Optimization       | 4.97         |
| Time-SampleProc         | 0.365        |
| Time-Sampling           | 469          |
| n_timesteps             | 270000       |
| train-AverageDiscoun... | 37           |
| train-AverageReturn     | 27.2         |
| train-EnvExecTime       | 5.73         |
| train-MaxReturn         | 30.1         |
| train-MinReturn         | 23.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 462          |
| train-StdReturn         | 1.39         |
------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 27          |
| ItrTime                 | 357         |
| LossAfter               | -0.2141435  |
| LossBefore              | 0.017946903 |
| Time                    | 6.54e+03    |
| Time-Optimization       | 7.3         |
| Time-SampleProc         | 0.0296      |
| Time-Sampling           | 350         |
| n_timesteps             | 280000      |
| train-AverageDiscoun... | 36.8        |
| train-AverageReturn     | 27.1        |
| train-EnvExecTime       | 4.33        |
| train-MaxReturn         | 30.3        |
| train-MinReturn         | 18.7        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 345         |
| train-StdReturn         | 1.48        |
-----------------------------------------

 ---------------- Iteration 28 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 28           |
| ItrTime                 | 382          |
| LossAfter               | -0.26972523  |
| LossBefore              | -0.008788967 |
| Time                    | 6.92e+03     |
| Time-Optimization       | 6.59         |
| Time-SampleProc         | 0.0748       |
| Time-Sampling           | 375          |
| n_timesteps             | 290000       |
| train-AverageDiscoun... | 36.4         |
| train-AverageReturn     | 26.9         |
| train-EnvExecTime       | 4.51         |
| train-MaxReturn         | 30.1         |
| train-MinReturn         | 14.6         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 370          |
| train-StdReturn         | 1.85         |
------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 29           |
| ItrTime                 | 338          |
| LossAfter               | -0.25655314  |
| LossBefore              | 0.0007002563 |
| Time                    | 7.26e+03     |
| Time-Optimization       | 5.25         |
| Time-SampleProc         | 0.0471       |
| Time-Sampling           | 333          |
| n_timesteps             | 300000       |
| train-AverageDiscoun... | 37.3         |
| train-AverageReturn     | 27.1         |
| train-EnvExecTime       | 4.69         |
| train-MaxReturn         | 31           |
| train-MinReturn         | 18.7         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 327          |
| train-StdReturn         | 1.82         |
------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 30          |
| ItrTime                 | 346         |
| LossAfter               | -0.24294448 |
| LossBefore              | 0.018504111 |
| Time                    | 7.61e+03    |
| Time-Optimization       | 5.95        |
| Time-SampleProc         | 0.0448      |
| Time-Sampling           | 340         |
| n_timesteps             | 310000      |
| train-AverageDiscoun... | 36.5        |
| train-AverageReturn     | 26.7        |
| train-EnvExecTime       | 4.36        |
| train-MaxReturn         | 30.1        |
| train-MinReturn         | 17.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 335         |
| train-StdReturn         | 2.26        |
-----------------------------------------

 ---------------- Iteration 31 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 31           |
| ItrTime                 | 237          |
| LossAfter               | -0.26560277  |
| LossBefore              | 0.0010788849 |
| Time                    | 7.84e+03     |
| Time-Optimization       | 4.37         |
| Time-SampleProc         | 0.0331       |
| Time-Sampling           | 233          |
| n_timesteps             | 320000       |
| train-AverageDiscoun... | 36.3         |
| train-AverageReturn     | 26.8         |
| train-EnvExecTime       | 4.32         |
| train-MaxReturn         | 30.4         |
| train-MinReturn         | 2.9          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 228          |
| train-StdReturn         | 2.93         |
------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 32          |
| ItrTime                 | 293         |
| LossAfter               | -0.30178678 |
| LossBefore              | 0.009304131 |
| Time                    | 8.14e+03    |
| Time-Optimization       | 6.29        |
| Time-SampleProc         | 0.028       |
| Time-Sampling           | 286         |
| n_timesteps             | 330000      |
| train-AverageDiscoun... | 36.9        |
| train-AverageReturn     | 27.1        |
| train-EnvExecTime       | 4.43        |
| train-MaxReturn         | 30.4        |
| train-MinReturn         | 19.4        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 282         |
| train-StdReturn         | 1.54        |
-----------------------------------------

 ---------------- Iteration 33 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 33          |
| ItrTime                 | 342         |
| LossAfter               | -0.3435676  |
| LossBefore              | -0.00969757 |
| Time                    | 8.48e+03    |
| Time-Optimization       | 4.8         |
| Time-SampleProc         | 0.0322      |
| Time-Sampling           | 337         |
| n_timesteps             | 340000      |
| train-AverageDiscoun... | 37.1        |
| train-AverageReturn     | 27.1        |
| train-EnvExecTime       | 4.61        |
| train-MaxReturn         | 30.3        |
| train-MinReturn         | 17.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 332         |
| train-StdReturn         | 1.93        |
-----------------------------------------

 ---------------- Iteration 34 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 34             |
| ItrTime                 | 243            |
| LossAfter               | -0.3421373     |
| LossBefore              | -0.00018799133 |
| Time                    | 8.72e+03       |
| Time-Optimization       | 3.51           |
| Time-SampleProc         | 0.11           |
| Time-Sampling           | 240            |
| n_timesteps             | 350000         |
| train-AverageDiscoun... | 36.3           |
| train-AverageReturn     | 26.8           |
| train-EnvExecTime       | 3.98           |
| train-MaxReturn         | 29.6           |
| train-MinReturn         | 13.7           |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 235            |
| train-StdReturn         | 2.33           |
--------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 35          |
| ItrTime                 | 191         |
| LossAfter               | -0.29179418 |
| LossBefore              | 0.009417952 |
| Time                    | 8.91e+03    |
| Time-Optimization       | 5.94        |
| Time-SampleProc         | 0.0915      |
| Time-Sampling           | 185         |
| n_timesteps             | 360000      |
| train-AverageDiscoun... | 37          |
| train-AverageReturn     | 26.9        |
| train-EnvExecTime       | 3.92        |
| train-MaxReturn         | 30.1        |
| train-MinReturn         | 9.2         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 181         |
| train-StdReturn         | 2.45        |
-----------------------------------------

 ---------------- Iteration 36 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 36           |
| ItrTime                 | 177          |
| LossAfter               | -0.3737117   |
| LossBefore              | -0.019148316 |
| Time                    | 9.09e+03     |
| Time-Optimization       | 3.38         |
| Time-SampleProc         | 0.0304       |
| Time-Sampling           | 174          |
| n_timesteps             | 370000       |
| train-AverageDiscoun... | 37           |
| train-AverageReturn     | 27.1         |
| train-EnvExecTime       | 3.95         |
| train-MaxReturn         | 31.6         |
| train-MinReturn         | 17.1         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 170          |
| train-StdReturn         | 1.74         |
------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 37           |
| ItrTime                 | 186          |
| LossAfter               | -0.36386088  |
| LossBefore              | -0.006523602 |
| Time                    | 9.28e+03     |
| Time-Optimization       | 4.59         |
| Time-SampleProc         | 0.0729       |
| Time-Sampling           | 181          |
| n_timesteps             | 380000       |
| train-AverageDiscoun... | 36.7         |
| train-AverageReturn     | 26.8         |
| train-EnvExecTime       | 3.99         |
| train-MaxReturn         | 29.5         |
| train-MinReturn         | -2.41        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 176          |
| train-StdReturn         | 3.2          |
------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 38          |
| ItrTime                 | 202         |
| LossAfter               | -0.38900226 |
| LossBefore              | 0.003590619 |
| Time                    | 9.48e+03    |
| Time-Optimization       | 4.9         |
| Time-SampleProc         | 0.0559      |
| Time-Sampling           | 197         |
| n_timesteps             | 390000      |
| train-AverageDiscoun... | 36.5        |
| train-AverageReturn     | 26.9        |
| train-EnvExecTime       | 4.07        |
| train-MaxReturn         | 30.5        |
| train-MinReturn         | -4.95       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 192         |
| train-StdReturn         | 3.61        |
-----------------------------------------

 ---------------- Iteration 39 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 39          |
| ItrTime                 | 221         |
| LossAfter               | -0.4125934  |
| LossBefore              | 0.010015165 |
| Time                    | 9.7e+03     |
| Time-Optimization       | 6.2         |
| Time-SampleProc         | 0.0251      |
| Time-Sampling           | 214         |
| n_timesteps             | 400000      |
| train-AverageDiscoun... | 36.4        |
| train-AverageReturn     | 26.5        |
| train-EnvExecTime       | 4.21        |
| train-MaxReturn         | 30          |
| train-MinReturn         | 15.8        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 210         |
| train-StdReturn         | 2.51        |
-----------------------------------------

 ---------------- Iteration 40 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 40            |
| ItrTime                 | 205           |
| LossAfter               | -0.43788964   |
| LossBefore              | -0.0049354522 |
| Time                    | 9.9e+03       |
| Time-Optimization       | 3.78          |
| Time-SampleProc         | 0.032         |
| Time-Sampling           | 201           |
| n_timesteps             | 410000        |
| train-AverageDiscoun... | 36.5          |
| train-AverageReturn     | 26.7          |
| train-EnvExecTime       | 3.89          |
| train-MaxReturn         | 30.6          |
| train-MinReturn         | 5.59          |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 197           |
| train-StdReturn         | 3.29          |
-------------------------------------------

 ---------------- Iteration 41 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 41          |
| ItrTime                 | 188         |
| LossAfter               | -0.44504258 |
| LossBefore              | 0.005577533 |
| Time                    | 1.01e+04    |
| Time-Optimization       | 5.72        |
| Time-SampleProc         | 0.0202      |
| Time-Sampling           | 182         |
| n_timesteps             | 420000      |
| train-AverageDiscoun... | 37.1        |
| train-AverageReturn     | 26.6        |
| train-EnvExecTime       | 3.81        |
| train-MaxReturn         | 30.9        |
| train-MinReturn         | 2.76        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 178         |
| train-StdReturn         | 3.27        |
-----------------------------------------

 ---------------- Iteration 42 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 42           |
| ItrTime                 | 186          |
| LossAfter               | -0.49438232  |
| LossBefore              | 0.0016522399 |
| Time                    | 1.03e+04     |
| Time-Optimization       | 4.09         |
| Time-SampleProc         | 0.0484       |
| Time-Sampling           | 182          |
| n_timesteps             | 430000       |
| train-AverageDiscoun... | 36.2         |
| train-AverageReturn     | 26.5         |
| train-EnvExecTime       | 3.95         |
| train-MaxReturn         | 30.9         |
| train-MinReturn         | 9.8          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 177          |
| train-StdReturn         | 3.82         |
------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 43          |
| ItrTime                 | 243         |
| LossAfter               | -0.48231864 |
| LossBefore              | 0.009278097 |
| Time                    | 1.05e+04    |
| Time-Optimization       | 3.94        |
| Time-SampleProc         | 0.0297      |
| Time-Sampling           | 240         |
| n_timesteps             | 440000      |
| train-AverageDiscoun... | 36.4        |
| train-AverageReturn     | 26.4        |
| train-EnvExecTime       | 3.96        |
| train-MaxReturn         | 29.6        |
| train-MinReturn         | 11.6        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 235         |
| train-StdReturn         | 3.06        |
-----------------------------------------

 ---------------- Iteration 44 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 44          |
| ItrTime                 | 191         |
| LossAfter               | -0.52225876 |
| LossBefore              | 0.020312494 |
| Time                    | 1.07e+04    |
| Time-Optimization       | 4.02        |
| Time-SampleProc         | 0.0217      |
| Time-Sampling           | 187         |
| n_timesteps             | 450000      |
| train-AverageDiscoun... | 35.8        |
| train-AverageReturn     | 26.1        |
| train-EnvExecTime       | 3.88        |
| train-MaxReturn         | 29.8        |
| train-MinReturn         | 3.94        |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 183         |
| train-StdReturn         | 3.53        |
-----------------------------------------

 ---------------- Iteration 45 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 45          |
| ItrTime                 | 185         |
| LossAfter               | -0.51206166 |
| LossBefore              | 0.019299367 |
| Time                    | 1.09e+04    |
| Time-Optimization       | 4.1         |
| Time-SampleProc         | 0.0421      |
| Time-Sampling           | 181         |
| n_timesteps             | 460000      |
| train-AverageDiscoun... | 35          |
| train-AverageReturn     | 25.3        |
| train-EnvExecTime       | 3.81        |
| train-MaxReturn         | 31.1        |
| train-MinReturn         | -2.23       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 176         |
| train-StdReturn         | 5.84        |
-----------------------------------------

 ---------------- Iteration 46 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 46           |
| ItrTime                 | 184          |
| LossAfter               | -0.62290484  |
| LossBefore              | 0.0067703417 |
| Time                    | 1.11e+04     |
| Time-Optimization       | 3.4          |
| Time-SampleProc         | 0.0233       |
| Time-Sampling           | 181          |
| n_timesteps             | 470000       |
| train-AverageDiscoun... | 35.7         |
| train-AverageReturn     | 25.8         |
| train-EnvExecTime       | 3.8          |
| train-MaxReturn         | 31.3         |
| train-MinReturn         | 6.46         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 176          |
| train-StdReturn         | 3.82         |
------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 47            |
| ItrTime                 | 201           |
| LossAfter               | -0.6635945    |
| LossBefore              | -0.0100392215 |
| Time                    | 1.13e+04      |
| Time-Optimization       | 7.99          |
| Time-SampleProc         | 0.0248        |
| Time-Sampling           | 193           |
| n_timesteps             | 480000        |
| train-AverageDiscoun... | 34.9          |
| train-AverageReturn     | 25.5          |
| train-EnvExecTime       | 4.01          |
| train-MaxReturn         | 30.8          |
| train-MinReturn         | -0.583        |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 189           |
| train-StdReturn         | 5.64          |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 48           |
| ItrTime                 | 325          |
| LossAfter               | -0.67707586  |
| LossBefore              | 0.0007359345 |
| Time                    | 1.16e+04     |
| Time-Optimization       | 5.21         |
| Time-SampleProc         | 0.0512       |
| Time-Sampling           | 320          |
| n_timesteps             | 490000       |
| train-AverageDiscoun... | 34.8         |
| train-AverageReturn     | 24.7         |
| train-EnvExecTime       | 4.82         |
| train-MaxReturn         | 30.7         |
| train-MinReturn         | 1.36         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 315          |
| train-StdReturn         | 6.39         |
------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 49           |
| ItrTime                 | 277          |
| LossAfter               | -0.75658894  |
| LossBefore              | -0.007791034 |
| Time                    | 1.19e+04     |
| Time-Optimization       | 8.44         |
| Time-SampleProc         | 0.0425       |
| Time-Sampling           | 268          |
| n_timesteps             | 500000       |
| train-AverageDiscoun... | 35.8         |
| train-AverageReturn     | 25.2         |
| train-EnvExecTime       | 4.55         |
| train-MaxReturn         | 29.8         |
| train-MinReturn         | 2.91         |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 263          |
| train-StdReturn         | 4.67         |
------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 50           |
| ItrTime                 | 295          |
| LossAfter               | -0.7734557   |
| LossBefore              | -0.019108003 |
| Time                    | 1.22e+04     |
| Time-Optimization       | 5.53         |
| Time-SampleProc         | 0.0728       |
| Time-Sampling           | 289          |
| n_timesteps             | 510000       |
| train-AverageDiscoun... | 35           |
| train-AverageReturn     | 25           |
| train-EnvExecTime       | 4.83         |
| train-MaxReturn         | 30.8         |
| train-MinReturn         | -5.47        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 284          |
| train-StdReturn         | 5.47         |
------------------------------------------

 ---------------- Iteration 51 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 51           |
| ItrTime                 | 474          |
| LossAfter               | -0.79719543  |
| LossBefore              | -0.010733633 |
| Time                    | 1.27e+04     |
| Time-Optimization       | 5.01         |
| Time-SampleProc         | 0.177        |
| Time-Sampling           | 469          |
| n_timesteps             | 520000       |
| train-AverageDiscoun... | 34.9         |
| train-AverageReturn     | 25.1         |
| train-EnvExecTime       | 5.07         |
| train-MaxReturn         | 31.3         |
| train-MinReturn         | -1.28        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 463          |
| train-StdReturn         | 6.31         |
------------------------------------------

 ---------------- Iteration 52 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 52          |
| ItrTime                 | 238         |
| LossAfter               | -0.72075164 |
| LossBefore              | 0.009697507 |
| Time                    | 1.29e+04    |
| Time-Optimization       | 4.18        |
| Time-SampleProc         | 0.0287      |
| Time-Sampling           | 234         |
| n_timesteps             | 530000      |
| train-AverageDiscoun... | 31.8        |
| train-AverageReturn     | 23.2        |
| train-EnvExecTime       | 4.09        |
| train-MaxReturn         | 31.6        |
| train-MinReturn         | -4.28       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 229         |
| train-StdReturn         | 8.39        |
-----------------------------------------

 ---------------- Iteration 53 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 53             |
| ItrTime                 | 239            |
| LossAfter               | -0.7161421     |
| LossBefore              | -0.00042866822 |
| Time                    | 1.31e+04       |
| Time-Optimization       | 4.11           |
| Time-SampleProc         | 0.0267         |
| Time-Sampling           | 235            |
| n_timesteps             | 540000         |
| train-AverageDiscoun... | 31.2           |
| train-AverageReturn     | 22.4           |
| train-EnvExecTime       | 4.47           |
| train-MaxReturn         | 30.9           |
| train-MinReturn         | -2.67          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 230            |
| train-StdReturn         | 8.54           |
--------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 54           |
| ItrTime                 | 253          |
| LossAfter               | -0.649496    |
| LossBefore              | -0.010685986 |
| Time                    | 1.34e+04     |
| Time-Optimization       | 4.6          |
| Time-SampleProc         | 0.0335       |
| Time-Sampling           | 248          |
| n_timesteps             | 550000       |
| train-AverageDiscoun... | 28.5         |
| train-AverageReturn     | 20.7         |
| train-EnvExecTime       | 4.34         |
| train-MaxReturn         | 31           |
| train-MinReturn         | -4.94        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 243          |
| train-StdReturn         | 8.75         |
------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 55            |
| ItrTime                 | 251           |
| LossAfter               | -0.64217216   |
| LossBefore              | -0.0016844512 |
| Time                    | 1.36e+04      |
| Time-Optimization       | 3.47          |
| Time-SampleProc         | 0.0216        |
| Time-Sampling           | 248           |
| n_timesteps             | 560000        |
| train-AverageDiscoun... | 29.3          |
| train-AverageReturn     | 21.3          |
| train-EnvExecTime       | 3.87          |
| train-MaxReturn         | 31.7          |
| train-MinReturn         | -4.16         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 243           |
| train-StdReturn         | 8.88          |
-------------------------------------------

 ---------------- Iteration 56 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 56           |
| ItrTime                 | 183          |
| LossAfter               | -0.5638431   |
| LossBefore              | 0.0010830505 |
| Time                    | 1.38e+04     |
| Time-Optimization       | 3.77         |
| Time-SampleProc         | 0.0244       |
| Time-Sampling           | 179          |
| n_timesteps             | 570000       |
| train-AverageDiscoun... | 27.6         |
| train-AverageReturn     | 20.2         |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 31.6         |
| train-MinReturn         | -7.47        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 175          |
| train-StdReturn         | 9.53         |
------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 57          |
| ItrTime                 | 174         |
| LossAfter               | -0.51635164 |
| LossBefore              | 0.012045002 |
| Time                    | 1.4e+04     |
| Time-Optimization       | 3.13        |
| Time-SampleProc         | 0.0212      |
| Time-Sampling           | 171         |
| n_timesteps             | 580000      |
| train-AverageDiscoun... | 24.7        |
| train-AverageReturn     | 18.1        |
| train-EnvExecTime       | 3.66        |
| train-MaxReturn         | 32          |
| train-MinReturn         | -7.11       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 167         |
| train-StdReturn         | 10.1        |
-----------------------------------------

 ---------------- Iteration 58 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 58           |
| ItrTime                 | 171          |
| LossAfter               | -0.59324247  |
| LossBefore              | -0.023550354 |
| Time                    | 1.42e+04     |
| Time-Optimization       | 2.97         |
| Time-SampleProc         | 0.0228       |
| Time-Sampling           | 168          |
| n_timesteps             | 590000       |
| train-AverageDiscoun... | 26.3         |
| train-AverageReturn     | 19.5         |
| train-EnvExecTime       | 3.71         |
| train-MaxReturn         | 32.6         |
| train-MinReturn         | -4.03        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 164          |
| train-StdReturn         | 8.66         |
------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 59           |
| ItrTime                 | 173          |
| LossAfter               | -0.5628905   |
| LossBefore              | 0.0042125243 |
| Time                    | 1.43e+04     |
| Time-Optimization       | 3.9          |
| Time-SampleProc         | 0.0195       |
| Time-Sampling           | 169          |
| n_timesteps             | 600000       |
| train-AverageDiscoun... | 24           |
| train-AverageReturn     | 18.3         |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 31.1         |
| train-MinReturn         | -7.42        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 165          |
| train-StdReturn         | 10.5         |
------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 60            |
| ItrTime                 | 189           |
| LossAfter               | -1.3136681    |
| LossBefore              | -0.0038809518 |
| Time                    | 1.45e+04      |
| Time-Optimization       | 5.14          |
| Time-SampleProc         | 0.0409        |
| Time-Sampling           | 184           |
| n_timesteps             | 610000        |
| train-AverageDiscoun... | 14.9          |
| train-AverageReturn     | 12.5          |
| train-EnvExecTime       | 3.85          |
| train-MaxReturn         | 30.4          |
| train-MinReturn         | -8.72         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 180           |
| train-StdReturn         | 11.5          |
-------------------------------------------

 ---------------- Iteration 61 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 61          |
| ItrTime                 | 186         |
| LossAfter               | -3.8480737  |
| LossBefore              | 0.008504468 |
| Time                    | 1.47e+04    |
| Time-Optimization       | 4.5         |
| Time-SampleProc         | 0.0191      |
| Time-Sampling           | 182         |
| n_timesteps             | 620000      |
| train-AverageDiscoun... | 11.2        |
| train-AverageReturn     | 10.2        |
| train-EnvExecTime       | 3.71        |
| train-MaxReturn         | 31.2        |
| train-MinReturn         | -12.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 177         |
| train-StdReturn         | 12.4        |
-----------------------------------------

 ---------------- Iteration 62 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 62           |
| ItrTime                 | 181          |
| LossAfter               | -6.8109765   |
| LossBefore              | 0.0031491455 |
| Time                    | 1.49e+04     |
| Time-Optimization       | 3.29         |
| Time-SampleProc         | 0.0205       |
| Time-Sampling           | 178          |
| n_timesteps             | 630000       |
| train-AverageDiscoun... | -1.36        |
| train-AverageReturn     | 2.89         |
| train-EnvExecTime       | 3.78         |
| train-MaxReturn         | 29.7         |
| train-MinReturn         | -12.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 174          |
| train-StdReturn         | 10.9         |
------------------------------------------

 ---------------- Iteration 63 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 63            |
| ItrTime                 | 182           |
| LossAfter               | -32.88823     |
| LossBefore              | -0.0012105835 |
| Time                    | 1.51e+04      |
| Time-Optimization       | 3.52          |
| Time-SampleProc         | 0.0205        |
| Time-Sampling           | 179           |
| n_timesteps             | 640000        |
| train-AverageDiscoun... | -13.4         |
| train-AverageReturn     | -4.77         |
| train-EnvExecTime       | 3.86          |
| train-MaxReturn         | 15.4          |
| train-MinReturn         | -12.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 174           |
| train-StdReturn         | 5.74          |
-------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 64            |
| ItrTime                 | 187           |
| LossAfter               | -23.303907    |
| LossBefore              | -0.0020906555 |
| Time                    | 1.53e+04      |
| Time-Optimization       | 3.22          |
| Time-SampleProc         | 0.0206        |
| Time-Sampling           | 183           |
| n_timesteps             | 650000        |
| train-AverageDiscoun... | -14.5         |
| train-AverageReturn     | -5.59         |
| train-EnvExecTime       | 3.84          |
| train-MaxReturn         | 5.23          |
| train-MinReturn         | -12.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 179           |
| train-StdReturn         | 3.56          |
-------------------------------------------

 ---------------- Iteration 65 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 65          |
| ItrTime                 | 185         |
| LossAfter               | -4.9282994  |
| LossBefore              | 0.017667033 |
| Time                    | 1.54e+04    |
| Time-Optimization       | 3.41        |
| Time-SampleProc         | 0.0185      |
| Time-Sampling           | 182         |
| n_timesteps             | 660000      |
| train-AverageDiscoun... | -11.7       |
| train-AverageReturn     | -4.45       |
| train-EnvExecTime       | 3.87        |
| train-MaxReturn         | 2.24        |
| train-MinReturn         | -13.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 178         |
| train-StdReturn         | 3.39        |
-----------------------------------------

 ---------------- Iteration 66 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 66          |
| ItrTime                 | 177         |
| LossAfter               | -2.844184   |
| LossBefore              | 0.007883394 |
| Time                    | 1.56e+04    |
| Time-Optimization       | 4.27        |
| Time-SampleProc         | 0.0189      |
| Time-Sampling           | 173         |
| n_timesteps             | 670000      |
| train-AverageDiscoun... | -15         |
| train-AverageReturn     | -9.58       |
| train-EnvExecTime       | 3.85        |
| train-MaxReturn         | 2.84        |
| train-MinReturn         | -17.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 168         |
| train-StdReturn         | 5.94        |
-----------------------------------------

 ---------------- Iteration 67 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 67           |
| ItrTime                 | 180          |
| LossAfter               | -3.189523    |
| LossBefore              | 0.0068888306 |
| Time                    | 1.58e+04     |
| Time-Optimization       | 4.01         |
| Time-SampleProc         | 0.0184       |
| Time-Sampling           | 176          |
| n_timesteps             | 680000       |
| train-AverageDiscoun... | -21.5        |
| train-AverageReturn     | -14.9        |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | -11.3        |
| train-MinReturn         | -18.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 172          |
| train-StdReturn         | 1.67         |
------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 68          |
| ItrTime                 | 172         |
| LossAfter               | -2.2084901  |
| LossBefore              | 0.029548025 |
| Time                    | 1.6e+04     |
| Time-Optimization       | 3.27        |
| Time-SampleProc         | 0.0195      |
| Time-Sampling           | 169         |
| n_timesteps             | 690000      |
| train-AverageDiscoun... | -21.4       |
| train-AverageReturn     | -14.7       |
| train-EnvExecTime       | 3.81        |
| train-MaxReturn         | -10.8       |
| train-MinReturn         | -18.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 165         |
| train-StdReturn         | 1.59        |
-----------------------------------------

 ---------------- Iteration 69 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 69           |
| ItrTime                 | 172          |
| LossAfter               | -8.214318    |
| LossBefore              | -0.004624797 |
| Time                    | 1.61e+04     |
| Time-Optimization       | 3.58         |
| Time-SampleProc         | 0.0199       |
| Time-Sampling           | 168          |
| n_timesteps             | 700000       |
| train-AverageDiscoun... | -20.8        |
| train-AverageReturn     | -14.2        |
| train-EnvExecTime       | 3.78         |
| train-MaxReturn         | -10.4        |
| train-MinReturn         | -17.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 164          |
| train-StdReturn         | 1.72         |
------------------------------------------

 ---------------- Iteration 70 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 70           |
| ItrTime                 | 177          |
| LossAfter               | -67.84405    |
| LossBefore              | 0.0022847503 |
| Time                    | 1.63e+04     |
| Time-Optimization       | 3.12         |
| Time-SampleProc         | 0.0187       |
| Time-Sampling           | 174          |
| n_timesteps             | 710000       |
| train-AverageDiscoun... | -20.5        |
| train-AverageReturn     | -14          |
| train-EnvExecTime       | 3.86         |
| train-MaxReturn         | -10.2        |
| train-MinReturn         | -18.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 170          |
| train-StdReturn         | 1.98         |
------------------------------------------

 ---------------- Iteration 71 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 71            |
| ItrTime                 | 166           |
| LossAfter               | -61.849686    |
| LossBefore              | -0.0006036743 |
| Time                    | 1.65e+04      |
| Time-Optimization       | 3.45          |
| Time-SampleProc         | 0.0191        |
| Time-Sampling           | 163           |
| n_timesteps             | 720000        |
| train-AverageDiscoun... | -19.9         |
| train-AverageReturn     | -13.4         |
| train-EnvExecTime       | 3.76          |
| train-MaxReturn         | -0.183        |
| train-MinReturn         | -18           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 159           |
| train-StdReturn         | 3.53          |
-------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 72         |
| ItrTime                 | 156        |
| LossAfter               | 2.9640508  |
| LossBefore              | 0.01878385 |
| Time                    | 1.66e+04   |
| Time-Optimization       | 3.44       |
| Time-SampleProc         | 0.061      |
| Time-Sampling           | 153        |
| n_timesteps             | 730000     |
| train-AverageDiscoun... | 19.6       |
| train-AverageReturn     | 7.69       |
| train-EnvExecTime       | 3.64       |
| train-MaxReturn         | 19.9       |
| train-MinReturn         | -3.57      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 149        |
| train-StdReturn         | 5.75       |
----------------------------------------

 ---------------- Iteration 73 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 73            |
| ItrTime                 | 161           |
| LossAfter               | 0.23279634    |
| LossBefore              | -0.0055172243 |
| Time                    | 1.68e+04      |
| Time-Optimization       | 4.13          |
| Time-SampleProc         | 0.0196        |
| Time-Sampling           | 157           |
| n_timesteps             | 740000        |
| train-AverageDiscoun... | 4.99          |
| train-AverageReturn     | 0.877         |
| train-EnvExecTime       | 3.59          |
| train-MaxReturn         | 16.3          |
| train-MinReturn         | -9.11         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 153           |
| train-StdReturn         | 4.83          |
-------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 74         |
| ItrTime                 | 170        |
| LossAfter               | 0.03381077 |
| LossBefore              | 0.01727406 |
| Time                    | 1.7e+04    |
| Time-Optimization       | 3.31       |
| Time-SampleProc         | 0.0184     |
| Time-Sampling           | 167        |
| n_timesteps             | 750000     |
| train-AverageDiscoun... | 2.56       |
| train-AverageReturn     | 0.333      |
| train-EnvExecTime       | 3.58       |
| train-MaxReturn         | 21         |
| train-MinReturn         | -17.6      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 163        |
| train-StdReturn         | 6.58       |
----------------------------------------

 ---------------- Iteration 75 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 75           |
| ItrTime                 | 172          |
| LossAfter               | -0.042612694 |
| LossBefore              | -0.015834862 |
| Time                    | 1.72e+04     |
| Time-Optimization       | 3.21         |
| Time-SampleProc         | 0.0197       |
| Time-Sampling           | 168          |
| n_timesteps             | 760000       |
| train-AverageDiscoun... | 0.703        |
| train-AverageReturn     | -0.174       |
| train-EnvExecTime       | 3.61         |
| train-MaxReturn         | 21.7         |
| train-MinReturn         | -17.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 164          |
| train-StdReturn         | 7.11         |
------------------------------------------

 ---------------- Iteration 76 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 76           |
| ItrTime                 | 167          |
| LossAfter               | 0.0039801393 |
| LossBefore              | 0.0151594905 |
| Time                    | 1.73e+04     |
| Time-Optimization       | 4.15         |
| Time-SampleProc         | 0.0272       |
| Time-Sampling           | 163          |
| n_timesteps             | 770000       |
| train-AverageDiscoun... | 5.05         |
| train-AverageReturn     | 1.99         |
| train-EnvExecTime       | 3.6          |
| train-MaxReturn         | 21.5         |
| train-MinReturn         | -15.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 159          |
| train-StdReturn         | 8.56         |
------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 77            |
| ItrTime                 | 173           |
| LossAfter               | -0.008409143  |
| LossBefore              | 0.00044714357 |
| Time                    | 1.75e+04      |
| Time-Optimization       | 3.55          |
| Time-SampleProc         | 0.0373        |
| Time-Sampling           | 169           |
| n_timesteps             | 780000        |
| train-AverageDiscoun... | 3.88          |
| train-AverageReturn     | 1.39          |
| train-EnvExecTime       | 3.67          |
| train-MaxReturn         | 26.5          |
| train-MinReturn         | -18           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 165           |
| train-StdReturn         | 10.2          |
-------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 78           |
| ItrTime                 | 167          |
| LossAfter               | -0.08698525  |
| LossBefore              | -0.014285968 |
| Time                    | 1.77e+04     |
| Time-Optimization       | 3.97         |
| Time-SampleProc         | 0.0209       |
| Time-Sampling           | 163          |
| n_timesteps             | 790000       |
| train-AverageDiscoun... | 8.78         |
| train-AverageReturn     | 4.26         |
| train-EnvExecTime       | 3.61         |
| train-MaxReturn         | 26           |
| train-MinReturn         | -18.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 159          |
| train-StdReturn         | 11.8         |
------------------------------------------

 ---------------- Iteration 79 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 79           |
| ItrTime                 | 177          |
| LossAfter               | -0.042042065 |
| LossBefore              | -0.005947046 |
| Time                    | 1.78e+04     |
| Time-Optimization       | 3.69         |
| Time-SampleProc         | 0.0197       |
| Time-Sampling           | 173          |
| n_timesteps             | 800000       |
| train-AverageDiscoun... | 9.15         |
| train-AverageReturn     | 4.41         |
| train-EnvExecTime       | 3.66         |
| train-MaxReturn         | 24.7         |
| train-MinReturn         | -17.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 169          |
| train-StdReturn         | 11.4         |
------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 80            |
| ItrTime                 | 172           |
| LossAfter               | -0.044650342  |
| LossBefore              | -0.0026420166 |
| Time                    | 1.8e+04       |
| Time-Optimization       | 3.48          |
| Time-SampleProc         | 0.0304        |
| Time-Sampling           | 168           |
| n_timesteps             | 810000        |
| train-AverageDiscoun... | 11.5          |
| train-AverageReturn     | 5.98          |
| train-EnvExecTime       | 3.66          |
| train-MaxReturn         | 28.1          |
| train-MinReturn         | -17.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 164           |
| train-StdReturn         | 12.4          |
-------------------------------------------

 ---------------- Iteration 81 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 81           |
| ItrTime                 | 176          |
| LossAfter               | -0.67572606  |
| LossBefore              | -0.012365906 |
| Time                    | 1.82e+04     |
| Time-Optimization       | 3.95         |
| Time-SampleProc         | 0.0183       |
| Time-Sampling           | 172          |
| n_timesteps             | 820000       |
| train-AverageDiscoun... | 7.22         |
| train-AverageReturn     | 3.24         |
| train-EnvExecTime       | 3.73         |
| train-MaxReturn         | 24.9         |
| train-MinReturn         | -18          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 168          |
| train-StdReturn         | 12.8         |
------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 82            |
| ItrTime                 | 176           |
| LossAfter               | -8.372203     |
| LossBefore              | -0.0032333618 |
| Time                    | 1.84e+04      |
| Time-Optimization       | 3.4           |
| Time-SampleProc         | 0.0468        |
| Time-Sampling           | 172           |
| n_timesteps             | 830000        |
| train-AverageDiscoun... | 2.48          |
| train-AverageReturn     | -0.0472       |
| train-EnvExecTime       | 3.83          |
| train-MaxReturn         | 24            |
| train-MinReturn         | -17.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 168           |
| train-StdReturn         | 11.7          |
-------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 83           |
| ItrTime                 | 169          |
| LossAfter               | -31.707644   |
| LossBefore              | 0.0040607546 |
| Time                    | 1.85e+04     |
| Time-Optimization       | 3.53         |
| Time-SampleProc         | 0.0196       |
| Time-Sampling           | 165          |
| n_timesteps             | 840000       |
| train-AverageDiscoun... | -9.96        |
| train-AverageReturn     | -7.35        |
| train-EnvExecTime       | 3.73         |
| train-MaxReturn         | 21.5         |
| train-MinReturn         | -17.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 161          |
| train-StdReturn         | 10.5         |
------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 84           |
| ItrTime                 | 176          |
| LossAfter               | -21.463362   |
| LossBefore              | -0.004993982 |
| Time                    | 1.87e+04     |
| Time-Optimization       | 4.88         |
| Time-SampleProc         | 0.019        |
| Time-Sampling           | 171          |
| n_timesteps             | 850000       |
| train-AverageDiscoun... | -10.4        |
| train-AverageReturn     | -7.87        |
| train-EnvExecTime       | 3.68         |
| train-MaxReturn         | 6.87         |
| train-MinReturn         | -16.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 167          |
| train-StdReturn         | 6.89         |
------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 85            |
| ItrTime                 | 172           |
| LossAfter               | 0.77764297    |
| LossBefore              | -0.0075798826 |
| Time                    | 1.89e+04      |
| Time-Optimization       | 3.52          |
| Time-SampleProc         | 0.0183        |
| Time-Sampling           | 168           |
| n_timesteps             | 860000        |
| train-AverageDiscoun... | -8.33         |
| train-AverageReturn     | -3.33         |
| train-EnvExecTime       | 3.73          |
| train-MaxReturn         | 6.13          |
| train-MinReturn         | -9.62         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 164           |
| train-StdReturn         | 3.29          |
-------------------------------------------

 ---------------- Iteration 86 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 86          |
| ItrTime                 | 166         |
| LossAfter               | 0.052309252 |
| LossBefore              | -0.01607411 |
| Time                    | 1.9e+04     |
| Time-Optimization       | 3.43        |
| Time-SampleProc         | 0.0353      |
| Time-Sampling           | 162         |
| n_timesteps             | 870000      |
| train-AverageDiscoun... | -11.1       |
| train-AverageReturn     | -4.21       |
| train-EnvExecTime       | 3.77        |
| train-MaxReturn         | 3.97        |
| train-MinReturn         | -12.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 158         |
| train-StdReturn         | 3.44        |
-----------------------------------------

 ---------------- Iteration 87 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 87          |
| ItrTime                 | 158         |
| LossAfter               | 0.012834891 |
| LossBefore              | 0.028608685 |
| Time                    | 1.92e+04    |
| Time-Optimization       | 3.79        |
| Time-SampleProc         | 0.0194      |
| Time-Sampling           | 154         |
| n_timesteps             | 880000      |
| train-AverageDiscoun... | -10.9       |
| train-AverageReturn     | -4.29       |
| train-EnvExecTime       | 3.79        |
| train-MaxReturn         | 1.25        |
| train-MinReturn         | -12         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 150         |
| train-StdReturn         | 3.02        |
-----------------------------------------

 ---------------- Iteration 88 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 88          |
| ItrTime                 | 168         |
| LossAfter               | 0.015027753 |
| LossBefore              | 0.027593121 |
| Time                    | 1.94e+04    |
| Time-Optimization       | 3.51        |
| Time-SampleProc         | 0.0188      |
| Time-Sampling           | 164         |
| n_timesteps             | 890000      |
| train-AverageDiscoun... | -5.57       |
| train-AverageReturn     | -2.43       |
| train-EnvExecTime       | 3.85        |
| train-MaxReturn         | 11.5        |
| train-MinReturn         | -10.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 160         |
| train-StdReturn         | 4.44        |
-----------------------------------------

 ---------------- Iteration 89 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 89           |
| ItrTime                 | 171          |
| LossAfter               | -0.004968237 |
| LossBefore              | -0.003270096 |
| Time                    | 1.95e+04     |
| Time-Optimization       | 3.57         |
| Time-SampleProc         | 0.0422       |
| Time-Sampling           | 168          |
| n_timesteps             | 900000       |
| train-AverageDiscoun... | -2.27        |
| train-AverageReturn     | -3.19        |
| train-EnvExecTime       | 3.87         |
| train-MaxReturn         | 8.42         |
| train-MinReturn         | -12.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 163          |
| train-StdReturn         | 5            |
------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 90           |
| ItrTime                 | 172          |
| LossAfter               | -8.98529e-05 |
| LossBefore              | -0.002517331 |
| Time                    | 1.97e+04     |
| Time-Optimization       | 3.72         |
| Time-SampleProc         | 0.0201       |
| Time-Sampling           | 168          |
| n_timesteps             | 910000       |
| train-AverageDiscoun... | -12.8        |
| train-AverageReturn     | -9.89        |
| train-EnvExecTime       | 4.03         |
| train-MaxReturn         | 7.3          |
| train-MinReturn         | -15.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 164          |
| train-StdReturn         | 4.13         |
------------------------------------------

 ---------------- Iteration 91 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 91            |
| ItrTime                 | 248           |
| LossAfter               | -0.0053814696 |
| LossBefore              | -0.0049095154 |
| Time                    | 2e+04         |
| Time-Optimization       | 4.91          |
| Time-SampleProc         | 0.0295        |
| Time-Sampling           | 243           |
| n_timesteps             | 920000        |
| train-AverageDiscoun... | -15.7         |
| train-AverageReturn     | -11.5         |
| train-EnvExecTime       | 4.9           |
| train-MaxReturn         | -2.03         |
| train-MinReturn         | -16           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 236           |
| train-StdReturn         | 2.2           |
-------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 92          |
| ItrTime                 | 282         |
| LossAfter               | 0.00447056  |
| LossBefore              | 0.004933911 |
| Time                    | 2.02e+04    |
| Time-Optimization       | 4.41        |
| Time-SampleProc         | 0.0311      |
| Time-Sampling           | 278         |
| n_timesteps             | 930000      |
| train-AverageDiscoun... | -16         |
| train-AverageReturn     | -11.7       |
| train-EnvExecTime       | 4.62        |
| train-MaxReturn         | -5.18       |
| train-MinReturn         | -15.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 272         |
| train-StdReturn         | 2.1         |
-----------------------------------------

 ---------------- Iteration 93 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 93            |
| ItrTime                 | 241           |
| LossAfter               | 0.0007584854  |
| LossBefore              | 0.00087394717 |
| Time                    | 2.05e+04      |
| Time-Optimization       | 4.92          |
| Time-SampleProc         | 0.0273        |
| Time-Sampling           | 236           |
| n_timesteps             | 940000        |
| train-AverageDiscoun... | -16.4         |
| train-AverageReturn     | -12           |
| train-EnvExecTime       | 4.61          |
| train-MaxReturn         | -2.46         |
| train-MinReturn         | -16.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 231           |
| train-StdReturn         | 2.08          |
-------------------------------------------

 ---------------- Iteration 94 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 94          |
| ItrTime                 | 139         |
| LossAfter               | 0.008798049 |
| LossBefore              | 0.008765712 |
| Time                    | 2.06e+04    |
| Time-Optimization       | 3.2         |
| Time-SampleProc         | 0.0252      |
| Time-Sampling           | 136         |
| n_timesteps             | 950000      |
| train-AverageDiscoun... | -16.5       |
| train-AverageReturn     | -11.9       |
| train-EnvExecTime       | 4.52        |
| train-MaxReturn         | -4.36       |
| train-MinReturn         | -16         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 131         |
| train-StdReturn         | 2.01        |
-----------------------------------------

 ---------------- Iteration 95 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 95           |
| ItrTime                 | 175          |
| LossAfter               | 0.0005521667 |
| LossBefore              | 0.001382309  |
| Time                    | 2.08e+04     |
| Time-Optimization       | 3.5          |
| Time-SampleProc         | 0.143        |
| Time-Sampling           | 171          |
| n_timesteps             | 960000       |
| train-AverageDiscoun... | -16.3        |
| train-AverageReturn     | -11.7        |
| train-EnvExecTime       | 4.51         |
| train-MaxReturn         | -6.3         |
| train-MinReturn         | -15.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 166          |
| train-StdReturn         | 1.82         |
------------------------------------------

 ---------------- Iteration 96 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 96             |
| ItrTime                 | 168            |
| LossAfter               | -0.00088359375 |
| LossBefore              | 0.00048641357  |
| Time                    | 2.1e+04        |
| Time-Optimization       | 3              |
| Time-SampleProc         | 0.0236         |
| Time-Sampling           | 165            |
| n_timesteps             | 970000         |
| train-AverageDiscoun... | -15.5          |
| train-AverageReturn     | -11.4          |
| train-EnvExecTime       | 4.55           |
| train-MaxReturn         | -1.28          |
| train-MinReturn         | -16.7          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 160            |
| train-StdReturn         | 2.64           |
--------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 97          |
| ItrTime                 | 133         |
| LossAfter               | 0.01716162  |
| LossBefore              | 0.019646332 |
| Time                    | 2.11e+04    |
| Time-Optimization       | 2.74        |
| Time-SampleProc         | 0.0207      |
| Time-Sampling           | 130         |
| n_timesteps             | 980000      |
| train-AverageDiscoun... | -15.1       |
| train-AverageReturn     | -11.1       |
| train-EnvExecTime       | 4.53        |
| train-MaxReturn         | 2.11        |
| train-MinReturn         | -15.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 125         |
| train-StdReturn         | 2.88        |
-----------------------------------------

 ---------------- Iteration 98 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 98            |
| ItrTime                 | 163           |
| LossAfter               | -0.0059270933 |
| LossBefore              | -0.0024996002 |
| Time                    | 2.13e+04      |
| Time-Optimization       | 2.81          |
| Time-SampleProc         | 0.0273        |
| Time-Sampling           | 161           |
| n_timesteps             | 990000        |
| train-AverageDiscoun... | -11.4         |
| train-AverageReturn     | -9.18         |
| train-EnvExecTime       | 4.62          |
| train-MaxReturn         | 3.45          |
| train-MinReturn         | -14.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 155           |
| train-StdReturn         | 3.83          |
-------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 99           |
| ItrTime                 | 158          |
| LossAfter               | 0.0053782286 |
| LossBefore              | 0.0075085172 |
| Time                    | 2.14e+04     |
| Time-Optimization       | 2.99         |
| Time-SampleProc         | 0.0209       |
| Time-Sampling           | 155          |
| n_timesteps             | 1000000      |
| train-AverageDiscoun... | -4.85        |
| train-AverageReturn     | -4.59        |
| train-EnvExecTime       | 4.5          |
| train-MaxReturn         | 10.6         |
| train-MinReturn         | -13.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 150          |
| train-StdReturn         | 5.22         |
------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 100          |
| ItrTime                 | 117          |
| LossAfter               | 0.007243994  |
| LossBefore              | 0.0070878663 |
| Time                    | 2.15e+04     |
| Time-Optimization       | 2.37         |
| Time-SampleProc         | 0.0213       |
| Time-Sampling           | 115          |
| n_timesteps             | 1010000      |
| train-AverageDiscoun... | -1.51        |
| train-AverageReturn     | -1.53        |
| train-EnvExecTime       | 4.09         |
| train-MaxReturn         | 9.25         |
| train-MinReturn         | -10.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 110          |
| train-StdReturn         | 4.36         |
------------------------------------------

 ---------------- Iteration 101 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 101           |
| ItrTime                 | 110           |
| LossAfter               | -0.003606134  |
| LossBefore              | 0.00074682315 |
| Time                    | 2.16e+04      |
| Time-Optimization       | 2.57          |
| Time-SampleProc         | 0.0284        |
| Time-Sampling           | 108           |
| n_timesteps             | 1020000       |
| train-AverageDiscoun... | -2.65         |
| train-AverageReturn     | -1.98         |
| train-EnvExecTime       | 3.95          |
| train-MaxReturn         | 10.7          |
| train-MinReturn         | -11.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 103           |
| train-StdReturn         | 4.56          |
-------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 102          |
| ItrTime                 | 114          |
| LossAfter               | 0.0031973724 |
| LossBefore              | 0.0038655181 |
| Time                    | 2.18e+04     |
| Time-Optimization       | 3.09         |
| Time-SampleProc         | 0.0198       |
| Time-Sampling           | 111          |
| n_timesteps             | 1030000      |
| train-AverageDiscoun... | -1.57        |
| train-AverageReturn     | -3.79        |
| train-EnvExecTime       | 3.99         |
| train-MaxReturn         | 9.36         |
| train-MinReturn         | -16.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 107          |
| train-StdReturn         | 5.63         |
------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 103           |
| ItrTime                 | 113           |
| LossAfter               | -0.009076703  |
| LossBefore              | -0.0077136415 |
| Time                    | 2.19e+04      |
| Time-Optimization       | 2.69          |
| Time-SampleProc         | 0.021         |
| Time-Sampling           | 110           |
| n_timesteps             | 1040000       |
| train-AverageDiscoun... | -10.8         |
| train-AverageReturn     | -8.72         |
| train-EnvExecTime       | 3.89          |
| train-MaxReturn         | 6.39          |
| train-MinReturn         | -16.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 106           |
| train-StdReturn         | 4.58          |
-------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 104         |
| ItrTime                 | 113         |
| LossAfter               | 0.013010608 |
| LossBefore              | 0.019524649 |
| Time                    | 2.2e+04     |
| Time-Optimization       | 2.74        |
| Time-SampleProc         | 0.0198      |
| Time-Sampling           | 110         |
| n_timesteps             | 1050000     |
| train-AverageDiscoun... | -6.82       |
| train-AverageReturn     | -6.54       |
| train-EnvExecTime       | 3.9         |
| train-MaxReturn         | 5.48        |
| train-MinReturn         | -14.1       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 106         |
| train-StdReturn         | 4.37        |
-----------------------------------------

 ---------------- Iteration 105 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 105           |
| ItrTime                 | 116           |
| LossAfter               | -0.005458301  |
| LossBefore              | -0.0077787964 |
| Time                    | 2.21e+04      |
| Time-Optimization       | 2.41          |
| Time-SampleProc         | 0.0211        |
| Time-Sampling           | 114           |
| n_timesteps             | 1060000       |
| train-AverageDiscoun... | -1.9          |
| train-AverageReturn     | -2.56         |
| train-EnvExecTime       | 3.9           |
| train-MaxReturn         | 8.86          |
| train-MinReturn         | -13.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 109           |
| train-StdReturn         | 4.59          |
-------------------------------------------

 ---------------- Iteration 106 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 106         |
| ItrTime                 | 119         |
| LossAfter               | 0.006953555 |
| LossBefore              | 0.010717712 |
| Time                    | 2.22e+04    |
| Time-Optimization       | 2.59        |
| Time-SampleProc         | 0.0447      |
| Time-Sampling           | 116         |
| n_timesteps             | 1070000     |
| train-AverageDiscoun... | -1.83       |
| train-AverageReturn     | -1.27       |
| train-EnvExecTime       | 3.94        |
| train-MaxReturn         | 7.24        |
| train-MinReturn         | -11.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 112         |
| train-StdReturn         | 3.92        |
-----------------------------------------

 ---------------- Iteration 107 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 107         |
| ItrTime                 | 113         |
| LossAfter               | 0.009290222 |
| LossBefore              | 0.013173944 |
| Time                    | 2.23e+04    |
| Time-Optimization       | 3.15        |
| Time-SampleProc         | 0.0146      |
| Time-Sampling           | 110         |
| n_timesteps             | 1080000     |
| train-AverageDiscoun... | -0.899      |
| train-AverageReturn     | -1.63       |
| train-EnvExecTime       | 3.83        |
| train-MaxReturn         | 9.73        |
| train-MinReturn         | -10.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 105         |
| train-StdReturn         | 4.54        |
-----------------------------------------

 ---------------- Iteration 108 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 108           |
| ItrTime                 | 111           |
| LossAfter               | -0.0030846435 |
| LossBefore              | -0.004398755  |
| Time                    | 2.24e+04      |
| Time-Optimization       | 2.69          |
| Time-SampleProc         | 0.0209        |
| Time-Sampling           | 109           |
| n_timesteps             | 1090000       |
| train-AverageDiscoun... | -7.29         |
| train-AverageReturn     | -6.91         |
| train-EnvExecTime       | 3.81          |
| train-MaxReturn         | 7.95          |
| train-MinReturn         | -15.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 104           |
| train-StdReturn         | 5.39          |
-------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 109         |
| ItrTime                 | 112         |
| LossAfter               | 0.013768091 |
| LossBefore              | 0.016564026 |
| Time                    | 2.26e+04    |
| Time-Optimization       | 2.7         |
| Time-SampleProc         | 0.0204      |
| Time-Sampling           | 109         |
| n_timesteps             | 1100000     |
| train-AverageDiscoun... | -12.5       |
| train-AverageReturn     | -9.45       |
| train-EnvExecTime       | 3.87        |
| train-MaxReturn         | 3.56        |
| train-MinReturn         | -15.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 105         |
| train-StdReturn         | 3.66        |
-----------------------------------------

 ---------------- Iteration 110 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 110          |
| ItrTime                 | 106          |
| LossAfter               | 0.0051272917 |
| LossBefore              | 0.0077239745 |
| Time                    | 2.27e+04     |
| Time-Optimization       | 2.74         |
| Time-SampleProc         | 0.0839       |
| Time-Sampling           | 104          |
| n_timesteps             | 1110000      |
| train-AverageDiscoun... | -4.93        |
| train-AverageReturn     | -5.05        |
| train-EnvExecTime       | 3.83         |
| train-MaxReturn         | 8.5          |
| train-MinReturn         | -14.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 99.3         |
| train-StdReturn         | 5.3          |
------------------------------------------

 ---------------- Iteration 111 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 111          |
| ItrTime                 | 108          |
| LossAfter               | 0.004942981  |
| LossBefore              | 0.0040299254 |
| Time                    | 2.28e+04     |
| Time-Optimization       | 3.03         |
| Time-SampleProc         | 0.0194       |
| Time-Sampling           | 105          |
| n_timesteps             | 1120000      |
| train-AverageDiscoun... | -2.39        |
| train-AverageReturn     | -1.96        |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 10.8         |
| train-MinReturn         | -11.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 100          |
| train-StdReturn         | 4.1          |
------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 112          |
| ItrTime                 | 116          |
| LossAfter               | 0.004279309  |
| LossBefore              | 0.0067679444 |
| Time                    | 2.29e+04     |
| Time-Optimization       | 2.69         |
| Time-SampleProc         | 0.0256       |
| Time-Sampling           | 113          |
| n_timesteps             | 1130000      |
| train-AverageDiscoun... | -1.08        |
| train-AverageReturn     | -1.45        |
| train-EnvExecTime       | 3.89         |
| train-MaxReturn         | 11.4         |
| train-MinReturn         | -10.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 109          |
| train-StdReturn         | 4.68         |
------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 113          |
| ItrTime                 | 115          |
| LossAfter               | -0.013016986 |
| LossBefore              | -0.012101886 |
| Time                    | 2.3e+04      |
| Time-Optimization       | 2.72         |
| Time-SampleProc         | 0.0507       |
| Time-Sampling           | 112          |
| n_timesteps             | 1140000      |
| train-AverageDiscoun... | -0.64        |
| train-AverageReturn     | -2.35        |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 8.86         |
| train-MinReturn         | -13.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 108          |
| train-StdReturn         | 4.86         |
------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 114          |
| ItrTime                 | 109          |
| LossAfter               | 0.0016248414 |
| LossBefore              | 0.0011576172 |
| Time                    | 2.31e+04     |
| Time-Optimization       | 2.45         |
| Time-SampleProc         | 0.0702       |
| Time-Sampling           | 106          |
| n_timesteps             | 1150000      |
| train-AverageDiscoun... | -2.75        |
| train-AverageReturn     | -4.45        |
| train-EnvExecTime       | 3.88         |
| train-MaxReturn         | 11.6         |
| train-MinReturn         | -13.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 102          |
| train-StdReturn         | 5.99         |
------------------------------------------

 ---------------- Iteration 115 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 115           |
| ItrTime                 | 107           |
| LossAfter               | -0.0062115174 |
| LossBefore              | -0.0024078551 |
| Time                    | 2.32e+04      |
| Time-Optimization       | 2.49          |
| Time-SampleProc         | 0.0199        |
| Time-Sampling           | 105           |
| n_timesteps             | 1160000       |
| train-AverageDiscoun... | -5.35         |
| train-AverageReturn     | -5.78         |
| train-EnvExecTime       | 3.82          |
| train-MaxReturn         | 9.65          |
| train-MinReturn         | -14.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 101           |
| train-StdReturn         | 5.1           |
-------------------------------------------

 ---------------- Iteration 116 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 116         |
| ItrTime                 | 109         |
| LossAfter               | 0.015883602 |
| LossBefore              | 0.01592891  |
| Time                    | 2.33e+04    |
| Time-Optimization       | 2.69        |
| Time-SampleProc         | 0.0199      |
| Time-Sampling           | 106         |
| n_timesteps             | 1170000     |
| train-AverageDiscoun... | -2.08       |
| train-AverageReturn     | -3.28       |
| train-EnvExecTime       | 3.86        |
| train-MaxReturn         | 10.1        |
| train-MinReturn         | -13.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 102         |
| train-StdReturn         | 4.84        |
-----------------------------------------

 ---------------- Iteration 117 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 117         |
| ItrTime                 | 108         |
| LossAfter               | 0.011999881 |
| LossBefore              | 0.01196748  |
| Time                    | 2.34e+04    |
| Time-Optimization       | 2.56        |
| Time-SampleProc         | 0.0463      |
| Time-Sampling           | 106         |
| n_timesteps             | 1180000     |
| train-AverageDiscoun... | -1.91       |
| train-AverageReturn     | -1.39       |
| train-EnvExecTime       | 3.83        |
| train-MaxReturn         | 9.06        |
| train-MinReturn         | -11.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 102         |
| train-StdReturn         | 4.6         |
-----------------------------------------

 ---------------- Iteration 118 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 118         |
| ItrTime                 | 113         |
| LossAfter               | 0.008720032 |
| LossBefore              | 0.012263513 |
| Time                    | 2.35e+04    |
| Time-Optimization       | 2.86        |
| Time-SampleProc         | 0.0194      |
| Time-Sampling           | 110         |
| n_timesteps             | 1190000     |
| train-AverageDiscoun... | -1.61       |
| train-AverageReturn     | -1.26       |
| train-EnvExecTime       | 3.82        |
| train-MaxReturn         | 12          |
| train-MinReturn         | -11         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 106         |
| train-StdReturn         | 4.61        |
-----------------------------------------

 ---------------- Iteration 119 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 119         |
| ItrTime                 | 105         |
| LossAfter               | 0.027929468 |
| LossBefore              | 0.030552588 |
| Time                    | 2.37e+04    |
| Time-Optimization       | 3.8         |
| Time-SampleProc         | 0.0585      |
| Time-Sampling           | 102         |
| n_timesteps             | 1200000     |
| train-AverageDiscoun... | -0.446      |
| train-AverageReturn     | -2.08       |
| train-EnvExecTime       | 3.82        |
| train-MaxReturn         | 10.3        |
| train-MinReturn         | -14.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 97.4        |
| train-StdReturn         | 5.01        |
-----------------------------------------

 ---------------- Iteration 120 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 120           |
| ItrTime                 | 109           |
| LossAfter               | -0.004126489  |
| LossBefore              | -0.0046855956 |
| Time                    | 2.38e+04      |
| Time-Optimization       | 3.04          |
| Time-SampleProc         | 0.0756        |
| Time-Sampling           | 106           |
| n_timesteps             | 1210000       |
| train-AverageDiscoun... | -9.37         |
| train-AverageReturn     | -7.83         |
| train-EnvExecTime       | 3.81          |
| train-MaxReturn         | 7.72          |
| train-MinReturn         | -15.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 102           |
| train-StdReturn         | 5.06          |
-------------------------------------------

 ---------------- Iteration 121 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 121          |
| ItrTime                 | 107          |
| LossAfter               | 0.0034501709 |
| LossBefore              | 0.00861521   |
| Time                    | 2.39e+04     |
| Time-Optimization       | 2.73         |
| Time-SampleProc         | 0.0203       |
| Time-Sampling           | 105          |
| n_timesteps             | 1220000      |
| train-AverageDiscoun... | -8.61        |
| train-AverageReturn     | -7.7         |
| train-EnvExecTime       | 3.83         |
| train-MaxReturn         | 10           |
| train-MinReturn         | -15.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 100          |
| train-StdReturn         | 4.78         |
------------------------------------------

 ---------------- Iteration 122 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 122           |
| ItrTime                 | 108           |
| LossAfter               | 4.5870973e-05 |
| LossBefore              | -0.0013593384 |
| Time                    | 2.4e+04       |
| Time-Optimization       | 2.56          |
| Time-SampleProc         | 0.0223        |
| Time-Sampling           | 105           |
| n_timesteps             | 1230000       |
| train-AverageDiscoun... | -0.597        |
| train-AverageReturn     | -2.38         |
| train-EnvExecTime       | 3.79          |
| train-MaxReturn         | 9.33          |
| train-MinReturn         | -13.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 101           |
| train-StdReturn         | 5.67          |
-------------------------------------------

 ---------------- Iteration 123 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 123          |
| ItrTime                 | 106          |
| LossAfter               | 0.0036774795 |
| LossBefore              | 0.0047340617 |
| Time                    | 2.41e+04     |
| Time-Optimization       | 2.72         |
| Time-SampleProc         | 0.0196       |
| Time-Sampling           | 103          |
| n_timesteps             | 1240000      |
| train-AverageDiscoun... | -1.79        |
| train-AverageReturn     | -1.81        |
| train-EnvExecTime       | 3.86         |
| train-MaxReturn         | 11.3         |
| train-MinReturn         | -11.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 98.8         |
| train-StdReturn         | 4.73         |
------------------------------------------

 ---------------- Iteration 124 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 124           |
| ItrTime                 | 103           |
| LossAfter               | -0.0008915893 |
| LossBefore              | 0.002006836   |
| Time                    | 2.42e+04      |
| Time-Optimization       | 2.61          |
| Time-SampleProc         | 0.0193        |
| Time-Sampling           | 100           |
| n_timesteps             | 1250000       |
| train-AverageDiscoun... | -2.72         |
| train-AverageReturn     | -2.24         |
| train-EnvExecTime       | 3.78          |
| train-MaxReturn         | 10.6          |
| train-MinReturn         | -11.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 96.3          |
| train-StdReturn         | 4.36          |
-------------------------------------------

 ---------------- Iteration 125 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 125          |
| ItrTime                 | 105          |
| LossAfter               | -0.013332721 |
| LossBefore              | -0.014185224 |
| Time                    | 2.43e+04     |
| Time-Optimization       | 3.1          |
| Time-SampleProc         | 0.0198       |
| Time-Sampling           | 102          |
| n_timesteps             | 1260000      |
| train-AverageDiscoun... | -4.44        |
| train-AverageReturn     | -4.95        |
| train-EnvExecTime       | 3.85         |
| train-MaxReturn         | 11.1         |
| train-MinReturn         | -15.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 97.5         |
| train-StdReturn         | 5.75         |
------------------------------------------

 ---------------- Iteration 126 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 126          |
| ItrTime                 | 111          |
| LossAfter               | -0.00924823  |
| LossBefore              | -0.008602234 |
| Time                    | 2.44e+04     |
| Time-Optimization       | 3.23         |
| Time-SampleProc         | 0.0489       |
| Time-Sampling           | 107          |
| n_timesteps             | 1270000      |
| train-AverageDiscoun... | -6.04        |
| train-AverageReturn     | -6.18        |
| train-EnvExecTime       | 3.82         |
| train-MaxReturn         | 6.94         |
| train-MinReturn         | -14.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 103          |
| train-StdReturn         | 5.56         |
------------------------------------------

 ---------------- Iteration 127 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 127          |
| ItrTime                 | 107          |
| LossAfter               | -0.008931052 |
| LossBefore              | -0.007115088 |
| Time                    | 2.45e+04     |
| Time-Optimization       | 3.04         |
| Time-SampleProc         | 0.0236       |
| Time-Sampling           | 104          |
| n_timesteps             | 1280000      |
| train-AverageDiscoun... | -2.88        |
| train-AverageReturn     | -4.24        |
| train-EnvExecTime       | 3.8          |
| train-MaxReturn         | 9.2          |
| train-MinReturn         | -13.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 100          |
| train-StdReturn         | 5.65         |
------------------------------------------

 ---------------- Iteration 128 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 128           |
| ItrTime                 | 114           |
| LossAfter               | -0.0051293457 |
| LossBefore              | -0.005648706  |
| Time                    | 2.46e+04      |
| Time-Optimization       | 2.83          |
| Time-SampleProc         | 0.0211        |
| Time-Sampling           | 111           |
| n_timesteps             | 1290000       |
| train-AverageDiscoun... | -2.81         |
| train-AverageReturn     | -3.04         |
| train-EnvExecTime       | 3.86          |
| train-MaxReturn         | 10.5          |
| train-MinReturn         | -14.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 107           |
| train-StdReturn         | 5.44          |
-------------------------------------------

 ---------------- Iteration 129 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 129            |
| ItrTime                 | 111            |
| LossAfter               | -0.0021240693  |
| LossBefore              | -0.00032534942 |
| Time                    | 2.47e+04       |
| Time-Optimization       | 2.76           |
| Time-SampleProc         | 0.0201         |
| Time-Sampling           | 108            |
| n_timesteps             | 1300000        |
| train-AverageDiscoun... | -2.88          |
| train-AverageReturn     | -2.46          |
| train-EnvExecTime       | 3.82           |
| train-MaxReturn         | 8.93           |
| train-MinReturn         | -14.1          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 104            |
| train-StdReturn         | 4.11           |
--------------------------------------------

 ---------------- Iteration 130 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 130          |
| ItrTime                 | 111          |
| LossAfter               | 0.0009813354 |
| LossBefore              | 0.0027890503 |
| Time                    | 2.48e+04     |
| Time-Optimization       | 3.26         |
| Time-SampleProc         | 0.0186       |
| Time-Sampling           | 108          |
| n_timesteps             | 1310000      |
| train-AverageDiscoun... | -0.431       |
| train-AverageReturn     | -1.7         |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 8.81         |
| train-MinReturn         | -12          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 104          |
| train-StdReturn         | 4.39         |
------------------------------------------

 ---------------- Iteration 131 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 131          |
| ItrTime                 | 110          |
| LossAfter               | 0.0070795226 |
| LossBefore              | 0.008731305  |
| Time                    | 2.5e+04      |
| Time-Optimization       | 3.2          |
| Time-SampleProc         | 0.0207       |
| Time-Sampling           | 107          |
| n_timesteps             | 1320000      |
| train-AverageDiscoun... | -7.13        |
| train-AverageReturn     | -6.24        |
| train-EnvExecTime       | 3.88         |
| train-MaxReturn         | 7.78         |
| train-MinReturn         | -15          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 102          |
| train-StdReturn         | 5.36         |
------------------------------------------

 ---------------- Iteration 132 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 132            |
| ItrTime                 | 117            |
| LossAfter               | -0.00010900879 |
| LossBefore              | 0.001620227    |
| Time                    | 2.51e+04       |
| Time-Optimization       | 2.76           |
| Time-SampleProc         | 0.028          |
| Time-Sampling           | 114            |
| n_timesteps             | 1330000        |
| train-AverageDiscoun... | -3.04          |
| train-AverageReturn     | -3.78          |
| train-EnvExecTime       | 4.34           |
| train-MaxReturn         | 11             |
| train-MinReturn         | -15.5          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 110            |
| train-StdReturn         | 5.84           |
--------------------------------------------

 ---------------- Iteration 133 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 133          |
| ItrTime                 | 108          |
| LossAfter               | 0.0006249878 |
| LossBefore              | 0.0005622009 |
| Time                    | 2.52e+04     |
| Time-Optimization       | 2.44         |
| Time-SampleProc         | 0.0214       |
| Time-Sampling           | 106          |
| n_timesteps             | 1340000      |
| train-AverageDiscoun... | -0.799       |
| train-AverageReturn     | -1.74        |
| train-EnvExecTime       | 3.73         |
| train-MaxReturn         | 9.09         |
| train-MinReturn         | -12.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 102          |
| train-StdReturn         | 4.75         |
------------------------------------------

 ---------------- Iteration 134 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 134          |
| ItrTime                 | 112          |
| LossAfter               | -0.012116487 |
| LossBefore              | -0.009338082 |
| Time                    | 2.53e+04     |
| Time-Optimization       | 2.46         |
| Time-SampleProc         | 0.0192       |
| Time-Sampling           | 109          |
| n_timesteps             | 1350000      |
| train-AverageDiscoun... | -2.23        |
| train-AverageReturn     | -1.93        |
| train-EnvExecTime       | 3.77         |
| train-MaxReturn         | 10.3         |
| train-MinReturn         | -10.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 105          |
| train-StdReturn         | 4.01         |
------------------------------------------

 ---------------- Iteration 135 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 135          |
| ItrTime                 | 112          |
| LossAfter               | 0.0009429504 |
| LossBefore              | 0.0024093566 |
| Time                    | 2.54e+04     |
| Time-Optimization       | 2.69         |
| Time-SampleProc         | 0.0186       |
| Time-Sampling           | 110          |
| n_timesteps             | 1360000      |
| train-AverageDiscoun... | -2.85        |
| train-AverageReturn     | -3.55        |
| train-EnvExecTime       | 3.73         |
| train-MaxReturn         | 9.68         |
| train-MinReturn         | -12.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 4.79         |
------------------------------------------

 ---------------- Iteration 136 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 136          |
| ItrTime                 | 111          |
| LossAfter               | 0.001239447  |
| LossBefore              | 0.0015354981 |
| Time                    | 2.55e+04     |
| Time-Optimization       | 2.58         |
| Time-SampleProc         | 0.021        |
| Time-Sampling           | 109          |
| n_timesteps             | 1370000      |
| train-AverageDiscoun... | -10.6        |
| train-AverageReturn     | -8.58        |
| train-EnvExecTime       | 3.67         |
| train-MaxReturn         | 7.91         |
| train-MinReturn         | -15.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 105          |
| train-StdReturn         | 4.59         |
------------------------------------------

 ---------------- Iteration 137 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 137           |
| ItrTime                 | 110           |
| LossAfter               | -0.012648895  |
| LossBefore              | -0.0052929167 |
| Time                    | 2.56e+04      |
| Time-Optimization       | 2.83          |
| Time-SampleProc         | 0.0187        |
| Time-Sampling           | 107           |
| n_timesteps             | 1380000       |
| train-AverageDiscoun... | -8.5          |
| train-AverageReturn     | -7.67         |
| train-EnvExecTime       | 3.66          |
| train-MaxReturn         | 9.03          |
| train-MinReturn         | -16.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 103           |
| train-StdReturn         | 5.12          |
-------------------------------------------

 ---------------- Iteration 138 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 138           |
| ItrTime                 | 108           |
| LossAfter               | -0.0107661495 |
| LossBefore              | -0.010914062  |
| Time                    | 2.57e+04      |
| Time-Optimization       | 2.97          |
| Time-SampleProc         | 0.0215        |
| Time-Sampling           | 105           |
| n_timesteps             | 1390000       |
| train-AverageDiscoun... | -1.07         |
| train-AverageReturn     | -2.29         |
| train-EnvExecTime       | 3.67          |
| train-MaxReturn         | 14            |
| train-MinReturn         | -11.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 101           |
| train-StdReturn         | 4.49          |
-------------------------------------------

 ---------------- Iteration 139 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 139           |
| ItrTime                 | 112           |
| LossAfter               | -0.004597461  |
| LossBefore              | -0.0039285216 |
| Time                    | 2.58e+04      |
| Time-Optimization       | 2.79          |
| Time-SampleProc         | 0.0171        |
| Time-Sampling           | 110           |
| n_timesteps             | 1400000       |
| train-AverageDiscoun... | -6.6          |
| train-AverageReturn     | -3            |
| train-EnvExecTime       | 3.83          |
| train-MaxReturn         | 5.69          |
| train-MinReturn         | -10.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 105           |
| train-StdReturn         | 3.5           |
-------------------------------------------

 ---------------- Iteration 140 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 140          |
| ItrTime                 | 107          |
| LossAfter               | -0.014865631 |
| LossBefore              | -0.009710675 |
| Time                    | 2.6e+04      |
| Time-Optimization       | 2.63         |
| Time-SampleProc         | 0.0194       |
| Time-Sampling           | 105          |
| n_timesteps             | 1410000      |
| train-AverageDiscoun... | -6.09        |
| train-AverageReturn     | -2.41        |
| train-EnvExecTime       | 3.67         |
| train-MaxReturn         | 6.57         |
| train-MinReturn         | -10.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 101          |
| train-StdReturn         | 3.93         |
------------------------------------------

 ---------------- Iteration 141 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 141          |
| ItrTime                 | 121          |
| LossAfter               | -0.007221411 |
| LossBefore              | -0.00556134  |
| Time                    | 2.61e+04     |
| Time-Optimization       | 3.05         |
| Time-SampleProc         | 0.116        |
| Time-Sampling           | 118          |
| n_timesteps             | 1420000      |
| train-AverageDiscoun... | -0.336       |
| train-AverageReturn     | -2.25        |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 9.73         |
| train-MinReturn         | -14.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 113          |
| train-StdReturn         | 5.16         |
------------------------------------------

 ---------------- Iteration 142 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 142           |
| ItrTime                 | 130           |
| LossAfter               | 0.00086000975 |
| LossBefore              | 0.00021453858 |
| Time                    | 2.62e+04      |
| Time-Optimization       | 3.8           |
| Time-SampleProc         | 0.0297        |
| Time-Sampling           | 126           |
| n_timesteps             | 1430000       |
| train-AverageDiscoun... | -8.73         |
| train-AverageReturn     | -7.67         |
| train-EnvExecTime       | 4.11          |
| train-MaxReturn         | 5.02          |
| train-MinReturn         | -15.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 122           |
| train-StdReturn         | 4.61          |
-------------------------------------------

 ---------------- Iteration 143 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 143          |
| ItrTime                 | 114          |
| LossAfter               | -0.014082715 |
| LossBefore              | -0.012959478 |
| Time                    | 2.63e+04     |
| Time-Optimization       | 3.03         |
| Time-SampleProc         | 0.0214       |
| Time-Sampling           | 111          |
| n_timesteps             | 1440000      |
| train-AverageDiscoun... | -8.56        |
| train-AverageReturn     | -7.6         |
| train-EnvExecTime       | 3.94         |
| train-MaxReturn         | 7.23         |
| train-MinReturn         | -14.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 4.8          |
------------------------------------------

 ---------------- Iteration 144 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 144          |
| ItrTime                 | 115          |
| LossAfter               | -0.006519873 |
| LossBefore              | 0.0043706056 |
| Time                    | 2.64e+04     |
| Time-Optimization       | 2.98         |
| Time-SampleProc         | 0.019        |
| Time-Sampling           | 112          |
| n_timesteps             | 1450000      |
| train-AverageDiscoun... | -7.5         |
| train-AverageReturn     | -6.86        |
| train-EnvExecTime       | 3.86         |
| train-MaxReturn         | 6.68         |
| train-MinReturn         | -16.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 108          |
| train-StdReturn         | 5.57         |
------------------------------------------

 ---------------- Iteration 145 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 145           |
| ItrTime                 | 125           |
| LossAfter               | -0.0023952636 |
| LossBefore              | -0.0049933656 |
| Time                    | 2.66e+04      |
| Time-Optimization       | 3.01          |
| Time-SampleProc         | 0.0592        |
| Time-Sampling           | 122           |
| n_timesteps             | 1460000       |
| train-AverageDiscoun... | -1.48         |
| train-AverageReturn     | -1.65         |
| train-EnvExecTime       | 4.6           |
| train-MaxReturn         | 11.8          |
| train-MinReturn         | -10.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 117           |
| train-StdReturn         | 4.3           |
-------------------------------------------

 ---------------- Iteration 146 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 146           |
| ItrTime                 | 143           |
| LossAfter               | -0.0003782959 |
| LossBefore              | 0.004772705   |
| Time                    | 2.67e+04      |
| Time-Optimization       | 2.69          |
| Time-SampleProc         | 0.0432        |
| Time-Sampling           | 140           |
| n_timesteps             | 1470000       |
| train-AverageDiscoun... | -6.63         |
| train-AverageReturn     | -2.67         |
| train-EnvExecTime       | 4.16          |
| train-MaxReturn         | 11.8          |
| train-MinReturn         | -13.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 136           |
| train-StdReturn         | 3.9           |
-------------------------------------------

 ---------------- Iteration 147 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 147          |
| ItrTime                 | 120          |
| LossAfter               | -0.017882153 |
| LossBefore              | -0.009092551 |
| Time                    | 2.68e+04     |
| Time-Optimization       | 3.25         |
| Time-SampleProc         | 0.0232       |
| Time-Sampling           | 117          |
| n_timesteps             | 1480000      |
| train-AverageDiscoun... | 0.00803      |
| train-AverageReturn     | -0.768       |
| train-EnvExecTime       | 4.06         |
| train-MaxReturn         | 11.4         |
| train-MinReturn         | -11.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 112          |
| train-StdReturn         | 4.21         |
------------------------------------------

 ---------------- Iteration 148 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 148          |
| ItrTime                 | 116          |
| LossAfter               | 0.004204608  |
| LossBefore              | 0.0018113831 |
| Time                    | 2.69e+04     |
| Time-Optimization       | 3.1          |
| Time-SampleProc         | 0.0205       |
| Time-Sampling           | 113          |
| n_timesteps             | 1490000      |
| train-AverageDiscoun... | -9.34        |
| train-AverageReturn     | -7.99        |
| train-EnvExecTime       | 3.95         |
| train-MaxReturn         | 8.92         |
| train-MinReturn         | -15.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 109          |
| train-StdReturn         | 4.88         |
------------------------------------------

 ---------------- Iteration 149 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 149         |
| ItrTime                 | 118         |
| LossAfter               | 0.020328628 |
| LossBefore              | 0.021612618 |
| Time                    | 2.71e+04    |
| Time-Optimization       | 3.22        |
| Time-SampleProc         | 0.0255      |
| Time-Sampling           | 115         |
| n_timesteps             | 1500000     |
| train-AverageDiscoun... | -14.8       |
| train-AverageReturn     | -11         |
| train-EnvExecTime       | 3.98        |
| train-MaxReturn         | 0.995       |
| train-MinReturn         | -16.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 110         |
| train-StdReturn         | 2.61        |
-----------------------------------------

 ---------------- Iteration 150 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 150          |
| ItrTime                 | 121          |
| LossAfter               | -0.005758337 |
| LossBefore              | 0.0012362183 |
| Time                    | 2.72e+04     |
| Time-Optimization       | 2.87         |
| Time-SampleProc         | 0.0214       |
| Time-Sampling           | 118          |
| n_timesteps             | 1510000      |
| train-AverageDiscoun... | -11.6        |
| train-AverageReturn     | -9.23        |
| train-EnvExecTime       | 3.88         |
| train-MaxReturn         | 9.5          |
| train-MinReturn         | -15.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 113          |
| train-StdReturn         | 4.22         |
------------------------------------------

 ---------------- Iteration 151 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 151           |
| ItrTime                 | 112           |
| LossAfter               | 0.00013955079 |
| LossBefore              | 0.00209198    |
| Time                    | 2.73e+04      |
| Time-Optimization       | 3.99          |
| Time-SampleProc         | 0.0344        |
| Time-Sampling           | 108           |
| n_timesteps             | 1520000       |
| train-AverageDiscoun... | -3.44         |
| train-AverageReturn     | -4.32         |
| train-EnvExecTime       | 3.72          |
| train-MaxReturn         | 10.6          |
| train-MinReturn         | -13           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 104           |
| train-StdReturn         | 5.66          |
-------------------------------------------

 ---------------- Iteration 152 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 152          |
| ItrTime                 | 110          |
| LossAfter               | 0.0034872405 |
| LossBefore              | 0.0048147463 |
| Time                    | 2.74e+04     |
| Time-Optimization       | 5.14         |
| Time-SampleProc         | 0.0158       |
| Time-Sampling           | 105          |
| n_timesteps             | 1530000      |
| train-AverageDiscoun... | -4.51        |
| train-AverageReturn     | -2.3         |
| train-EnvExecTime       | 3.67         |
| train-MaxReturn         | 12           |
| train-MinReturn         | -13.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 101          |
| train-StdReturn         | 4.8          |
------------------------------------------

 ---------------- Iteration 153 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 153           |
| ItrTime                 | 106           |
| LossAfter               | -0.0005540222 |
| LossBefore              | 0.012164173   |
| Time                    | 2.75e+04      |
| Time-Optimization       | 2.9           |
| Time-SampleProc         | 0.0202        |
| Time-Sampling           | 104           |
| n_timesteps             | 1540000       |
| train-AverageDiscoun... | -5.02         |
| train-AverageReturn     | -2.61         |
| train-EnvExecTime       | 3.66          |
| train-MaxReturn         | 8.26          |
| train-MinReturn         | -10.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 99.5          |
| train-StdReturn         | 4.13          |
-------------------------------------------

 ---------------- Iteration 154 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 154           |
| ItrTime                 | 113           |
| LossAfter               | -0.005728259  |
| LossBefore              | -0.0072467285 |
| Time                    | 2.76e+04      |
| Time-Optimization       | 2.62          |
| Time-SampleProc         | 0.163         |
| Time-Sampling           | 110           |
| n_timesteps             | 1550000       |
| train-AverageDiscoun... | -5.11         |
| train-AverageReturn     | -4.95         |
| train-EnvExecTime       | 3.7           |
| train-MaxReturn         | 7.47          |
| train-MinReturn         | -15.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 106           |
| train-StdReturn         | 5.22          |
-------------------------------------------

 ---------------- Iteration 155 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 155          |
| ItrTime                 | 109          |
| LossAfter               | 0.0069292327 |
| LossBefore              | 0.0072100037 |
| Time                    | 2.77e+04     |
| Time-Optimization       | 2.45         |
| Time-SampleProc         | 0.0252       |
| Time-Sampling           | 107          |
| n_timesteps             | 1560000      |
| train-AverageDiscoun... | -11.2        |
| train-AverageReturn     | -9.55        |
| train-EnvExecTime       | 3.79         |
| train-MaxReturn         | 11.3         |
| train-MinReturn         | -15.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 103          |
| train-StdReturn         | 4.71         |
------------------------------------------

 ---------------- Iteration 156 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 156          |
| ItrTime                 | 115          |
| LossAfter               | 0.0066399626 |
| LossBefore              | 0.0071201357 |
| Time                    | 2.78e+04     |
| Time-Optimization       | 2.99         |
| Time-SampleProc         | 0.0196       |
| Time-Sampling           | 112          |
| n_timesteps             | 1570000      |
| train-AverageDiscoun... | -13          |
| train-AverageReturn     | -9.99        |
| train-EnvExecTime       | 3.99         |
| train-MaxReturn         | 4.27         |
| train-MinReturn         | -16.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 107          |
| train-StdReturn         | 3.23         |
------------------------------------------

 ---------------- Iteration 157 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 157          |
| ItrTime                 | 113          |
| LossAfter               | -0.008719629 |
| LossBefore              | -0.004327087 |
| Time                    | 2.8e+04      |
| Time-Optimization       | 3.26         |
| Time-SampleProc         | 0.0189       |
| Time-Sampling           | 110          |
| n_timesteps             | 1580000      |
| train-AverageDiscoun... | -9.69        |
| train-AverageReturn     | -8.41        |
| train-EnvExecTime       | 3.78         |
| train-MaxReturn         | 4.57         |
| train-MinReturn         | -14.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 3.93         |
------------------------------------------

 ---------------- Iteration 158 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 158           |
| ItrTime                 | 111           |
| LossAfter               | -0.0038054732 |
| LossBefore              | -0.0037102264 |
| Time                    | 2.81e+04      |
| Time-Optimization       | 2.8           |
| Time-SampleProc         | 0.0234        |
| Time-Sampling           | 108           |
| n_timesteps             | 1590000       |
| train-AverageDiscoun... | -1.35         |
| train-AverageReturn     | -2.58         |
| train-EnvExecTime       | 3.69          |
| train-MaxReturn         | 11.4          |
| train-MinReturn         | -12.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 104           |
| train-StdReturn         | 5.09          |
-------------------------------------------

 ---------------- Iteration 159 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 159           |
| ItrTime                 | 108           |
| LossAfter               | -0.007144168  |
| LossBefore              | -0.0054242783 |
| Time                    | 2.82e+04      |
| Time-Optimization       | 2.43          |
| Time-SampleProc         | 0.0198        |
| Time-Sampling           | 106           |
| n_timesteps             | 1600000       |
| train-AverageDiscoun... | -3.05         |
| train-AverageReturn     | -1.65         |
| train-EnvExecTime       | 3.72          |
| train-MaxReturn         | 7.78          |
| train-MinReturn         | -10.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 101           |
| train-StdReturn         | 3.85          |
-------------------------------------------

 ---------------- Iteration 160 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 160          |
| ItrTime                 | 120          |
| LossAfter               | 0.0031727783 |
| LossBefore              | 0.007832592  |
| Time                    | 2.83e+04     |
| Time-Optimization       | 2.84         |
| Time-SampleProc         | 0.0299       |
| Time-Sampling           | 117          |
| n_timesteps             | 1610000      |
| train-AverageDiscoun... | -0.473       |
| train-AverageReturn     | -0.913       |
| train-EnvExecTime       | 3.79         |
| train-MaxReturn         | 9.26         |
| train-MinReturn         | -9.97        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 113          |
| train-StdReturn         | 4.25         |
------------------------------------------

 ---------------- Iteration 161 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 161           |
| ItrTime                 | 110           |
| LossAfter               | -0.0011095825 |
| LossBefore              | -0.0023280028 |
| Time                    | 2.84e+04      |
| Time-Optimization       | 2.76          |
| Time-SampleProc         | 0.0289        |
| Time-Sampling           | 107           |
| n_timesteps             | 1620000       |
| train-AverageDiscoun... | -6.09         |
| train-AverageReturn     | -6.11         |
| train-EnvExecTime       | 3.65          |
| train-MaxReturn         | 9.28          |
| train-MinReturn         | -13.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 103           |
| train-StdReturn         | 5.52          |
-------------------------------------------

 ---------------- Iteration 162 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 162          |
| ItrTime                 | 111          |
| LossAfter               | -0.015412645 |
| LossBefore              | -0.011346903 |
| Time                    | 2.85e+04     |
| Time-Optimization       | 2.74         |
| Time-SampleProc         | 0.0222       |
| Time-Sampling           | 108          |
| n_timesteps             | 1630000      |
| train-AverageDiscoun... | -10.9        |
| train-AverageReturn     | -8.78        |
| train-EnvExecTime       | 3.67         |
| train-MaxReturn         | 10.2         |
| train-MinReturn         | -15.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 104          |
| train-StdReturn         | 4.68         |
------------------------------------------

 ---------------- Iteration 163 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 163           |
| ItrTime                 | 111           |
| LossAfter               | -0.009356006  |
| LossBefore              | -0.0023986327 |
| Time                    | 2.86e+04      |
| Time-Optimization       | 2.63          |
| Time-SampleProc         | 0.0175        |
| Time-Sampling           | 109           |
| n_timesteps             | 1640000       |
| train-AverageDiscoun... | -6.53         |
| train-AverageReturn     | -5.87         |
| train-EnvExecTime       | 3.73          |
| train-MaxReturn         | 10.2          |
| train-MinReturn         | -13.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 104           |
| train-StdReturn         | 5.38          |
-------------------------------------------

 ---------------- Iteration 164 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 164         |
| ItrTime                 | 112         |
| LossAfter               | 0.017720124 |
| LossBefore              | 0.01611911  |
| Time                    | 2.87e+04    |
| Time-Optimization       | 2.84        |
| Time-SampleProc         | 0.0212      |
| Time-Sampling           | 109         |
| n_timesteps             | 1650000     |
| train-AverageDiscoun... | -1.9        |
| train-AverageReturn     | -1.72       |
| train-EnvExecTime       | 3.8         |
| train-MaxReturn         | 13.7        |
| train-MinReturn         | -11.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 105         |
| train-StdReturn         | 5           |
-----------------------------------------

 ---------------- Iteration 165 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 165          |
| ItrTime                 | 111          |
| LossAfter               | -0.013824774 |
| LossBefore              | -0.00442959  |
| Time                    | 2.89e+04     |
| Time-Optimization       | 2.63         |
| Time-SampleProc         | 0.0202       |
| Time-Sampling           | 108          |
| n_timesteps             | 1660000      |
| train-AverageDiscoun... | -4.09        |
| train-AverageReturn     | -1.95        |
| train-EnvExecTime       | 3.74         |
| train-MaxReturn         | 12.2         |
| train-MinReturn         | -11.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 104          |
| train-StdReturn         | 3.95         |
------------------------------------------

 ---------------- Iteration 166 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 166         |
| ItrTime                 | 110         |
| LossAfter               | 0.012717854 |
| LossBefore              | 0.011121731 |
| Time                    | 2.9e+04     |
| Time-Optimization       | 2.86        |
| Time-SampleProc         | 0.0208      |
| Time-Sampling           | 107         |
| n_timesteps             | 1670000     |
| train-AverageDiscoun... | -4.79       |
| train-AverageReturn     | -4.92       |
| train-EnvExecTime       | 3.7         |
| train-MaxReturn         | 6.98        |
| train-MinReturn         | -14.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 103         |
| train-StdReturn         | 5.1         |
-----------------------------------------

 ---------------- Iteration 167 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 167          |
| ItrTime                 | 107          |
| LossAfter               | 0.0020768547 |
| LossBefore              | 0.0027532708 |
| Time                    | 2.91e+04     |
| Time-Optimization       | 2.91         |
| Time-SampleProc         | 0.0418       |
| Time-Sampling           | 104          |
| n_timesteps             | 1680000      |
| train-AverageDiscoun... | -14.6        |
| train-AverageReturn     | -10.8        |
| train-EnvExecTime       | 3.69         |
| train-MaxReturn         | 8.04         |
| train-MinReturn         | -15          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 99.7         |
| train-StdReturn         | 3.3          |
------------------------------------------

 ---------------- Iteration 168 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 168           |
| ItrTime                 | 105           |
| LossAfter               | -0.0022582032 |
| LossBefore              | -0.0013031708 |
| Time                    | 2.92e+04      |
| Time-Optimization       | 3.62          |
| Time-SampleProc         | 0.0193        |
| Time-Sampling           | 101           |
| n_timesteps             | 1690000       |
| train-AverageDiscoun... | -13.7         |
| train-AverageReturn     | -10.4         |
| train-EnvExecTime       | 3.68          |
| train-MaxReturn         | 4.04          |
| train-MinReturn         | -16.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 97.2          |
| train-StdReturn         | 3.03          |
-------------------------------------------

 ---------------- Iteration 169 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 169           |
| ItrTime                 | 107           |
| LossAfter               | -0.011221927  |
| LossBefore              | -0.0021608276 |
| Time                    | 2.93e+04      |
| Time-Optimization       | 3.73          |
| Time-SampleProc         | 0.0196        |
| Time-Sampling           | 103           |
| n_timesteps             | 1700000       |
| train-AverageDiscoun... | -10.3         |
| train-AverageReturn     | -8.42         |
| train-EnvExecTime       | 3.79          |
| train-MaxReturn         | 4.53          |
| train-MinReturn         | -17.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 99.1          |
| train-StdReturn         | 4.51          |
-------------------------------------------

 ---------------- Iteration 170 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 170          |
| ItrTime                 | 110          |
| LossAfter               | 0.009219949  |
| LossBefore              | 0.0070691276 |
| Time                    | 2.94e+04     |
| Time-Optimization       | 4.99         |
| Time-SampleProc         | 0.0234       |
| Time-Sampling           | 105          |
| n_timesteps             | 1710000      |
| train-AverageDiscoun... | -1.24        |
| train-AverageReturn     | -2.09        |
| train-EnvExecTime       | 3.81         |
| train-MaxReturn         | 8.32         |
| train-MinReturn         | -12.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 101          |
| train-StdReturn         | 4.83         |
------------------------------------------

 ---------------- Iteration 171 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 171         |
| ItrTime                 | 112         |
| LossAfter               | 0.012054395 |
| LossBefore              | 0.014348169 |
| Time                    | 2.95e+04    |
| Time-Optimization       | 2.63        |
| Time-SampleProc         | 0.0234      |
| Time-Sampling           | 109         |
| n_timesteps             | 1720000     |
| train-AverageDiscoun... | -5.93       |
| train-AverageReturn     | -2.7        |
| train-EnvExecTime       | 3.72        |
| train-MaxReturn         | 6.49        |
| train-MinReturn         | -10.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 105         |
| train-StdReturn         | 3.67        |
-----------------------------------------

 ---------------- Iteration 172 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 172            |
| ItrTime                 | 110            |
| LossAfter               | -0.0073579834  |
| LossBefore              | -1.5957641e-05 |
| Time                    | 2.96e+04       |
| Time-Optimization       | 2.59           |
| Time-SampleProc         | 0.0196         |
| Time-Sampling           | 107            |
| n_timesteps             | 1730000        |
| train-AverageDiscoun... | -1.44          |
| train-AverageReturn     | -1.14          |
| train-EnvExecTime       | 3.7            |
| train-MaxReturn         | 8.64           |
| train-MinReturn         | -9.35          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 103            |
| train-StdReturn         | 4.08           |
--------------------------------------------

 ---------------- Iteration 173 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 173         |
| ItrTime                 | 111         |
| LossAfter               | 0.008113043 |
| LossBefore              | 0.005635754 |
| Time                    | 2.97e+04    |
| Time-Optimization       | 3.76        |
| Time-SampleProc         | 0.0191      |
| Time-Sampling           | 108         |
| n_timesteps             | 1740000     |
| train-AverageDiscoun... | -4.78       |
| train-AverageReturn     | -5.69       |
| train-EnvExecTime       | 3.69        |
| train-MaxReturn         | 8.46        |
| train-MinReturn         | -14.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 104         |
| train-StdReturn         | 5.49        |
-----------------------------------------

 ---------------- Iteration 174 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 174         |
| ItrTime                 | 110         |
| LossAfter               | 0.008131671 |
| LossBefore              | 0.016811687 |
| Time                    | 2.98e+04    |
| Time-Optimization       | 3.35        |
| Time-SampleProc         | 0.0552      |
| Time-Sampling           | 106         |
| n_timesteps             | 1750000     |
| train-AverageDiscoun... | -10.3       |
| train-AverageReturn     | -8.74       |
| train-EnvExecTime       | 3.77        |
| train-MaxReturn         | 4.03        |
| train-MinReturn         | -15.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 102         |
| train-StdReturn         | 4.59        |
-----------------------------------------

 ---------------- Iteration 175 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 175          |
| ItrTime                 | 115          |
| LossAfter               | -0.012734509 |
| LossBefore              | -0.0100254   |
| Time                    | 2.99e+04     |
| Time-Optimization       | 2.69         |
| Time-SampleProc         | 0.0206       |
| Time-Sampling           | 112          |
| n_timesteps             | 1760000      |
| train-AverageDiscoun... | -1.12        |
| train-AverageReturn     | -3.29        |
| train-EnvExecTime       | 3.91         |
| train-MaxReturn         | 12.1         |
| train-MinReturn         | -13.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 108          |
| train-StdReturn         | 6.3          |
------------------------------------------

 ---------------- Iteration 176 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 176         |
| ItrTime                 | 114         |
| LossAfter               | 0.008841675 |
| LossBefore              | 0.009567816 |
| Time                    | 3.01e+04    |
| Time-Optimization       | 3.74        |
| Time-SampleProc         | 0.0194      |
| Time-Sampling           | 110         |
| n_timesteps             | 1770000     |
| train-AverageDiscoun... | -5.19       |
| train-AverageReturn     | -2.53       |
| train-EnvExecTime       | 3.75        |
| train-MaxReturn         | 7.24        |
| train-MinReturn         | -11.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 106         |
| train-StdReturn         | 3.95        |
-----------------------------------------

 ---------------- Iteration 177 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 177          |
| ItrTime                 | 113          |
| LossAfter               | -0.011209308 |
| LossBefore              | 0.0046321596 |
| Time                    | 3.02e+04     |
| Time-Optimization       | 2.47         |
| Time-SampleProc         | 0.0195       |
| Time-Sampling           | 111          |
| n_timesteps             | 1780000      |
| train-AverageDiscoun... | -4.5         |
| train-AverageReturn     | -2.2         |
| train-EnvExecTime       | 3.73         |
| train-MaxReturn         | 11.1         |
| train-MinReturn         | -11.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 107          |
| train-StdReturn         | 4            |
------------------------------------------

 ---------------- Iteration 178 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 178           |
| ItrTime                 | 109           |
| LossAfter               | 0.003415869   |
| LossBefore              | -0.0005029419 |
| Time                    | 3.03e+04      |
| Time-Optimization       | 2.51          |
| Time-SampleProc         | 0.0217        |
| Time-Sampling           | 106           |
| n_timesteps             | 1790000       |
| train-AverageDiscoun... | -8.55         |
| train-AverageReturn     | -7.15         |
| train-EnvExecTime       | 3.77          |
| train-MaxReturn         | 10.4          |
| train-MinReturn         | -15.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 102           |
| train-StdReturn         | 5.19          |
-------------------------------------------

 ---------------- Iteration 179 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 179         |
| ItrTime                 | 110         |
| LossAfter               | 0.009039374 |
| LossBefore              | 0.010708819 |
| Time                    | 3.04e+04    |
| Time-Optimization       | 2.52        |
| Time-SampleProc         | 0.0213      |
| Time-Sampling           | 107         |
| n_timesteps             | 1800000     |
| train-AverageDiscoun... | -14.7       |
| train-AverageReturn     | -11.2       |
| train-EnvExecTime       | 3.79        |
| train-MaxReturn         | 1.52        |
| train-MinReturn         | -15.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 103         |
| train-StdReturn         | 2.86        |
-----------------------------------------

 ---------------- Iteration 180 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 180         |
| ItrTime                 | 111         |
| LossAfter               | 0.014366485 |
| LossBefore              | 0.016116299 |
| Time                    | 3.05e+04    |
| Time-Optimization       | 2.7         |
| Time-SampleProc         | 0.0198      |
| Time-Sampling           | 108         |
| n_timesteps             | 1810000     |
| train-AverageDiscoun... | -14.3       |
| train-AverageReturn     | -10.9       |
| train-EnvExecTime       | 3.9         |
| train-MaxReturn         | 1.53        |
| train-MinReturn         | -15.5       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 104         |
| train-StdReturn         | 3.21        |
-----------------------------------------

 ---------------- Iteration 181 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 181         |
| ItrTime                 | 117         |
| LossAfter               | 0.004929852 |
| LossBefore              | 0.013151172 |
| Time                    | 3.06e+04    |
| Time-Optimization       | 2.53        |
| Time-SampleProc         | 0.0186      |
| Time-Sampling           | 114         |
| n_timesteps             | 1820000     |
| train-AverageDiscoun... | -12.3       |
| train-AverageReturn     | -9.41       |
| train-EnvExecTime       | 3.87        |
| train-MaxReturn         | 5.82        |
| train-MinReturn         | -14.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 110         |
| train-StdReturn         | 3.68        |
-----------------------------------------

 ---------------- Iteration 182 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 182          |
| ItrTime                 | 113          |
| LossAfter               | 0.006974457  |
| LossBefore              | 0.0040418943 |
| Time                    | 3.07e+04     |
| Time-Optimization       | 3.12         |
| Time-SampleProc         | 0.0187       |
| Time-Sampling           | 110          |
| n_timesteps             | 1830000      |
| train-AverageDiscoun... | -0.741       |
| train-AverageReturn     | -2.02        |
| train-EnvExecTime       | 3.9          |
| train-MaxReturn         | 10.2         |
| train-MinReturn         | -13.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 5.2          |
------------------------------------------

 ---------------- Iteration 183 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 183          |
| ItrTime                 | 115          |
| LossAfter               | 0.0010835816 |
| LossBefore              | 0.004159979  |
| Time                    | 3.08e+04     |
| Time-Optimization       | 2.58         |
| Time-SampleProc         | 0.0201       |
| Time-Sampling           | 113          |
| n_timesteps             | 1840000      |
| train-AverageDiscoun... | -4.53        |
| train-AverageReturn     | -2.15        |
| train-EnvExecTime       | 3.86         |
| train-MaxReturn         | 8.75         |
| train-MinReturn         | -10.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 108          |
| train-StdReturn         | 3.68         |
------------------------------------------

 ---------------- Iteration 184 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 184          |
| ItrTime                 | 113          |
| LossAfter               | -0.011524875 |
| LossBefore              | -0.010112938 |
| Time                    | 3.1e+04      |
| Time-Optimization       | 2.88         |
| Time-SampleProc         | 0.0219       |
| Time-Sampling           | 111          |
| n_timesteps             | 1850000      |
| train-AverageDiscoun... | -1.19        |
| train-AverageReturn     | -2.14        |
| train-EnvExecTime       | 3.94         |
| train-MaxReturn         | 9.39         |
| train-MinReturn         | -12.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 4.71         |
------------------------------------------

 ---------------- Iteration 185 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 185           |
| ItrTime                 | 112           |
| LossAfter               | 0.00027390136 |
| LossBefore              | 0.00067065126 |
| Time                    | 3.11e+04      |
| Time-Optimization       | 2.81          |
| Time-SampleProc         | 0.0184        |
| Time-Sampling           | 109           |
| n_timesteps             | 1860000       |
| train-AverageDiscoun... | -4.41         |
| train-AverageReturn     | -5.31         |
| train-EnvExecTime       | 3.86          |
| train-MaxReturn         | 8.72          |
| train-MinReturn         | -13.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 105           |
| train-StdReturn         | 5.69          |
-------------------------------------------

 ---------------- Iteration 186 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 186          |
| ItrTime                 | 112          |
| LossAfter               | -0.008390991 |
| LossBefore              | -0.002405475 |
| Time                    | 3.12e+04     |
| Time-Optimization       | 3.17         |
| Time-SampleProc         | 0.0205       |
| Time-Sampling           | 109          |
| n_timesteps             | 1870000      |
| train-AverageDiscoun... | -5.6         |
| train-AverageReturn     | -5.69        |
| train-EnvExecTime       | 3.96         |
| train-MaxReturn         | 8.36         |
| train-MinReturn         | -14          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 105          |
| train-StdReturn         | 5.4          |
------------------------------------------

 ---------------- Iteration 187 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 187          |
| ItrTime                 | 111          |
| LossAfter               | -0.021595666 |
| LossBefore              | -0.023428235 |
| Time                    | 3.13e+04     |
| Time-Optimization       | 2.61         |
| Time-SampleProc         | 0.0191       |
| Time-Sampling           | 109          |
| n_timesteps             | 1880000      |
| train-AverageDiscoun... | -3.08        |
| train-AverageReturn     | -2.27        |
| train-EnvExecTime       | 3.9          |
| train-MaxReturn         | 8.32         |
| train-MinReturn         | -10.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 104          |
| train-StdReturn         | 4.34         |
------------------------------------------

 ---------------- Iteration 188 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 188          |
| ItrTime                 | 110          |
| LossAfter               | 0.0069967317 |
| LossBefore              | 0.010595749  |
| Time                    | 3.14e+04     |
| Time-Optimization       | 2.42         |
| Time-SampleProc         | 0.0455       |
| Time-Sampling           | 107          |
| n_timesteps             | 1890000      |
| train-AverageDiscoun... | -1.81        |
| train-AverageReturn     | -1.45        |
| train-EnvExecTime       | 3.86         |
| train-MaxReturn         | 10.1         |
| train-MinReturn         | -11          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 103          |
| train-StdReturn         | 4.36         |
------------------------------------------

 ---------------- Iteration 189 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 189           |
| ItrTime                 | 110           |
| LossAfter               | -0.0042317077 |
| LossBefore              | -0.0031969727 |
| Time                    | 3.15e+04      |
| Time-Optimization       | 2.71          |
| Time-SampleProc         | 0.0217        |
| Time-Sampling           | 108           |
| n_timesteps             | 1900000       |
| train-AverageDiscoun... | -1.76         |
| train-AverageReturn     | -2.8          |
| train-EnvExecTime       | 3.89          |
| train-MaxReturn         | 9.63          |
| train-MinReturn         | -14           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 103           |
| train-StdReturn         | 5.06          |
-------------------------------------------

 ---------------- Iteration 190 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 190          |
| ItrTime                 | 101          |
| LossAfter               | -0.018006317 |
| LossBefore              | -0.01637832  |
| Time                    | 3.16e+04     |
| Time-Optimization       | 2.45         |
| Time-SampleProc         | 0.0197       |
| Time-Sampling           | 98.8         |
| n_timesteps             | 1910000      |
| train-AverageDiscoun... | -7.56        |
| train-AverageReturn     | -6.95        |
| train-EnvExecTime       | 3.81         |
| train-MaxReturn         | 5.99         |
| train-MinReturn         | -14.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 94.6         |
| train-StdReturn         | 5.06         |
------------------------------------------

 ---------------- Iteration 191 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 191           |
| ItrTime                 | 105           |
| LossAfter               | -0.017716063  |
| LossBefore              | -0.0038519164 |
| Time                    | 3.17e+04      |
| Time-Optimization       | 3.09          |
| Time-SampleProc         | 0.0217        |
| Time-Sampling           | 101           |
| n_timesteps             | 1920000       |
| train-AverageDiscoun... | -6.03         |
| train-AverageReturn     | -5.86         |
| train-EnvExecTime       | 3.85          |
| train-MaxReturn         | 10.2          |
| train-MinReturn         | -14.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 97.2          |
| train-StdReturn         | 5.28          |
-------------------------------------------

 ---------------- Iteration 192 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 192          |
| ItrTime                 | 111          |
| LossAfter               | -0.009248762 |
| LossBefore              | -0.011895627 |
| Time                    | 3.18e+04     |
| Time-Optimization       | 2.87         |
| Time-SampleProc         | 0.0192       |
| Time-Sampling           | 108          |
| n_timesteps             | 1930000      |
| train-AverageDiscoun... | -6.85        |
| train-AverageReturn     | -2.74        |
| train-EnvExecTime       | 3.8          |
| train-MaxReturn         | 5.44         |
| train-MinReturn         | -10.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 104          |
| train-StdReturn         | 3.52         |
------------------------------------------

 ---------------- Iteration 193 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 193           |
| ItrTime                 | 118           |
| LossAfter               | -0.0047884523 |
| LossBefore              | 0.0062695923  |
| Time                    | 3.2e+04       |
| Time-Optimization       | 2.96          |
| Time-SampleProc         | 0.0194        |
| Time-Sampling           | 115           |
| n_timesteps             | 1940000       |
| train-AverageDiscoun... | -8.53         |
| train-AverageReturn     | -3.56         |
| train-EnvExecTime       | 3.85          |
| train-MaxReturn         | 6.07          |
| train-MinReturn         | -9.85         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 111           |
| train-StdReturn         | 3.31          |
-------------------------------------------

 ---------------- Iteration 194 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 194         |
| ItrTime                 | 112         |
| LossAfter               | 0.014762915 |
| LossBefore              | 0.02029049  |
| Time                    | 3.21e+04    |
| Time-Optimization       | 2.35        |
| Time-SampleProc         | 0.0191      |
| Time-Sampling           | 110         |
| n_timesteps             | 1950000     |
| train-AverageDiscoun... | -1.57       |
| train-AverageReturn     | -2.31       |
| train-EnvExecTime       | 3.85        |
| train-MaxReturn         | 6.51        |
| train-MinReturn         | -12.8       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 106         |
| train-StdReturn         | 4.64        |
-----------------------------------------

 ---------------- Iteration 195 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 195          |
| ItrTime                 | 112          |
| LossAfter               | -0.010126013 |
| LossBefore              | -0.012525058 |
| Time                    | 3.22e+04     |
| Time-Optimization       | 2.36         |
| Time-SampleProc         | 0.0193       |
| Time-Sampling           | 110          |
| n_timesteps             | 1960000      |
| train-AverageDiscoun... | -14.5        |
| train-AverageReturn     | -10.8        |
| train-EnvExecTime       | 3.9          |
| train-MaxReturn         | -0.234       |
| train-MinReturn         | -15.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 105          |
| train-StdReturn         | 2.76         |
------------------------------------------

 ---------------- Iteration 196 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 196          |
| ItrTime                 | 141          |
| LossAfter               | 0.0026517394 |
| LossBefore              | 0.002616565  |
| Time                    | 3.23e+04     |
| Time-Optimization       | 2.51         |
| Time-SampleProc         | 0.0202       |
| Time-Sampling           | 138          |
| n_timesteps             | 1970000      |
| train-AverageDiscoun... | -16.3        |
| train-AverageReturn     | -12          |
| train-EnvExecTime       | 3.87         |
| train-MaxReturn         | -5.91        |
| train-MinReturn         | -17.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 134          |
| train-StdReturn         | 2.01         |
------------------------------------------

 ---------------- Iteration 197 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 197           |
| ItrTime                 | 108           |
| LossAfter               | -0.0041592256 |
| LossBefore              | -0.0039065825 |
| Time                    | 3.24e+04      |
| Time-Optimization       | 2.34          |
| Time-SampleProc         | 0.019         |
| Time-Sampling           | 105           |
| n_timesteps             | 1980000       |
| train-AverageDiscoun... | -17           |
| train-AverageReturn     | -12.2         |
| train-EnvExecTime       | 3.81          |
| train-MaxReturn         | -8.06         |
| train-MinReturn         | -16.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 101           |
| train-StdReturn         | 1.9           |
-------------------------------------------

 ---------------- Iteration 198 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 198           |
| ItrTime                 | 111           |
| LossAfter               | -0.0078003174 |
| LossBefore              | -0.0074589904 |
| Time                    | 3.25e+04      |
| Time-Optimization       | 2.37          |
| Time-SampleProc         | 0.0208        |
| Time-Sampling           | 108           |
| n_timesteps             | 1990000       |
| train-AverageDiscoun... | -15.8         |
| train-AverageReturn     | -11.5         |
| train-EnvExecTime       | 3.8           |
| train-MaxReturn         | -2.61         |
| train-MinReturn         | -16.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 104           |
| train-StdReturn         | 2.25          |
-------------------------------------------

 ---------------- Iteration 199 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 199          |
| ItrTime                 | 110          |
| LossAfter               | 0.0013401611 |
| LossBefore              | 0.0068105957 |
| Time                    | 3.26e+04     |
| Time-Optimization       | 2.94         |
| Time-SampleProc         | 0.0192       |
| Time-Sampling           | 107          |
| n_timesteps             | 2000000      |
| train-AverageDiscoun... | -14          |
| train-AverageReturn     | -10.6        |
| train-EnvExecTime       | 4.02         |
| train-MaxReturn         | -0.575       |
| train-MinReturn         | -14.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 103          |
| train-StdReturn         | 3            |
------------------------------------------

 ---------------- Iteration 200 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 200         |
| ItrTime                 | 125         |
| LossAfter               | 0.012576074 |
| LossBefore              | 0.025781598 |
| Time                    | 3.28e+04    |
| Time-Optimization       | 2.56        |
| Time-SampleProc         | 0.0314      |
| Time-Sampling           | 123         |
| n_timesteps             | 2010000     |
| train-AverageDiscoun... | -9.08       |
| train-AverageReturn     | -7.55       |
| train-EnvExecTime       | 4.05        |
| train-MaxReturn         | 5.12        |
| train-MinReturn         | -14.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 118         |
| train-StdReturn         | 4.84        |
-----------------------------------------

 ---------------- Iteration 201 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 201           |
| ItrTime                 | 122           |
| LossAfter               | -0.0042965086 |
| LossBefore              | -0.009130628  |
| Time                    | 3.29e+04      |
| Time-Optimization       | 2.64          |
| Time-SampleProc         | 0.0292        |
| Time-Sampling           | 119           |
| n_timesteps             | 2020000       |
| train-AverageDiscoun... | -5.58         |
| train-AverageReturn     | -2.59         |
| train-EnvExecTime       | 4.42          |
| train-MaxReturn         | 4.86          |
| train-MinReturn         | -12           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 115           |
| train-StdReturn         | 3.8           |
-------------------------------------------

 ---------------- Iteration 202 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 202          |
| ItrTime                 | 112          |
| LossAfter               | 0.005514941  |
| LossBefore              | 0.0067485473 |
| Time                    | 3.3e+04      |
| Time-Optimization       | 2.43         |
| Time-SampleProc         | 0.0228       |
| Time-Sampling           | 110          |
| n_timesteps             | 2030000      |
| train-AverageDiscoun... | -10.8        |
| train-AverageReturn     | -4.36        |
| train-EnvExecTime       | 4.21         |
| train-MaxReturn         | 7.01         |
| train-MinReturn         | -12          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 105          |
| train-StdReturn         | 3.75         |
------------------------------------------

 ---------------- Iteration 203 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 203          |
| ItrTime                 | 112          |
| LossAfter               | 0.0025821442 |
| LossBefore              | 0.007873846  |
| Time                    | 3.31e+04     |
| Time-Optimization       | 2.5          |
| Time-SampleProc         | 0.0375       |
| Time-Sampling           | 109          |
| n_timesteps             | 2040000      |
| train-AverageDiscoun... | -8.96        |
| train-AverageReturn     | -3.66        |
| train-EnvExecTime       | 3.92         |
| train-MaxReturn         | 5.96         |
| train-MinReturn         | -12          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 105          |
| train-StdReturn         | 3.76         |
------------------------------------------

 ---------------- Iteration 204 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 204           |
| ItrTime                 | 110           |
| LossAfter               | -0.0024116088 |
| LossBefore              | 0.004444171   |
| Time                    | 3.32e+04      |
| Time-Optimization       | 2.82          |
| Time-SampleProc         | 0.02          |
| Time-Sampling           | 107           |
| n_timesteps             | 2050000       |
| train-AverageDiscoun... | -1.14         |
| train-AverageReturn     | -1.4          |
| train-EnvExecTime       | 3.93          |
| train-MaxReturn         | 7.79          |
| train-MinReturn         | -12.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 102           |
| train-StdReturn         | 3.99          |
-------------------------------------------

 ---------------- Iteration 205 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 205          |
| ItrTime                 | 7.26e+03     |
| LossAfter               | -0.010192413 |
| LossBefore              | -0.01265564  |
| Time                    | 4.05e+04     |
| Time-Optimization       | 3.11         |
| Time-SampleProc         | 0.0543       |
| Time-Sampling           | 7.26e+03     |
| n_timesteps             | 2060000      |
| train-AverageDiscoun... | -8.39        |
| train-AverageReturn     | -7.31        |
| train-EnvExecTime       | 4.38         |
| train-MaxReturn         | 7.14         |
| train-MinReturn         | -15          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 7.25e+03     |
| train-StdReturn         | 5.02         |
------------------------------------------

 ---------------- Iteration 206 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 206           |
| ItrTime                 | 114           |
| LossAfter               | -0.004024347  |
| LossBefore              | -0.0018734771 |
| Time                    | 4.06e+04      |
| Time-Optimization       | 3.41          |
| Time-SampleProc         | 0.0225        |
| Time-Sampling           | 111           |
| n_timesteps             | 2070000       |
| train-AverageDiscoun... | -13.8         |
| train-AverageReturn     | -10.5         |
| train-EnvExecTime       | 3.86          |
| train-MaxReturn         | 0.78          |
| train-MinReturn         | -15.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 106           |
| train-StdReturn         | 3.09          |
-------------------------------------------

 ---------------- Iteration 207 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 207           |
| ItrTime                 | 138           |
| LossAfter               | -0.0022869506 |
| LossBefore              | 0.012329608   |
| Time                    | 4.07e+04      |
| Time-Optimization       | 2.63          |
| Time-SampleProc         | 0.0333        |
| Time-Sampling           | 136           |
| n_timesteps             | 2080000       |
| train-AverageDiscoun... | -10.1         |
| train-AverageReturn     | -8.29         |
| train-EnvExecTime       | 4             |
| train-MaxReturn         | 4.95          |
| train-MinReturn         | -15.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 131           |
| train-StdReturn         | 4.26          |
-------------------------------------------

 ---------------- Iteration 208 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 208          |
| ItrTime                 | 121          |
| LossAfter               | 0.011618164  |
| LossBefore              | 0.0066171633 |
| Time                    | 4.09e+04     |
| Time-Optimization       | 4.75         |
| Time-SampleProc         | 0.0461       |
| Time-Sampling           | 116          |
| n_timesteps             | 2090000      |
| train-AverageDiscoun... | -3.08        |
| train-AverageReturn     | -1.56        |
| train-EnvExecTime       | 3.98         |
| train-MaxReturn         | 7.57         |
| train-MinReturn         | -9.75        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 112          |
| train-StdReturn         | 3.88         |
------------------------------------------

 ---------------- Iteration 209 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 209         |
| ItrTime                 | 114         |
| LossAfter               | 0.008174518 |
| LossBefore              | 0.011002893 |
| Time                    | 4.1e+04     |
| Time-Optimization       | 2.72        |
| Time-SampleProc         | 0.0219      |
| Time-Sampling           | 111         |
| n_timesteps             | 2100000     |
| train-AverageDiscoun... | -9.8        |
| train-AverageReturn     | -3.86       |
| train-EnvExecTime       | 3.82        |
| train-MaxReturn         | 4           |
| train-MinReturn         | -11.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 107         |
| train-StdReturn         | 3.4         |
-----------------------------------------

 ---------------- Iteration 210 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 210           |
| ItrTime                 | 154           |
| LossAfter               | -0.0009884674 |
| LossBefore              | 0.00915148    |
| Time                    | 4.11e+04      |
| Time-Optimization       | 5.45          |
| Time-SampleProc         | 0.0389        |
| Time-Sampling           | 148           |
| n_timesteps             | 2110000       |
| train-AverageDiscoun... | -5.47         |
| train-AverageReturn     | -2.53         |
| train-EnvExecTime       | 4.03          |
| train-MaxReturn         | 5.36          |
| train-MinReturn         | -11.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 144           |
| train-StdReturn         | 3.55          |
-------------------------------------------

 ---------------- Iteration 211 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 211           |
| ItrTime                 | 171           |
| LossAfter               | 1.4306641e-05 |
| LossBefore              | -0.0012639893 |
| Time                    | 4.13e+04      |
| Time-Optimization       | 2.71          |
| Time-SampleProc         | 0.0218        |
| Time-Sampling           | 168           |
| n_timesteps             | 2120000       |
| train-AverageDiscoun... | -4.48         |
| train-AverageReturn     | -4.5          |
| train-EnvExecTime       | 4.19          |
| train-MaxReturn         | 10.3          |
| train-MinReturn         | -13.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 163           |
| train-StdReturn         | 5.58          |
-------------------------------------------

 ---------------- Iteration 212 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 212          |
| ItrTime                 | 129          |
| LossAfter               | 0.0035941529 |
| LossBefore              | 0.003804541  |
| Time                    | 4.14e+04     |
| Time-Optimization       | 3.09         |
| Time-SampleProc         | 0.0252       |
| Time-Sampling           | 126          |
| n_timesteps             | 2130000      |
| train-AverageDiscoun... | -12.2        |
| train-AverageReturn     | -9.84        |
| train-EnvExecTime       | 3.89         |
| train-MaxReturn         | 6.87         |
| train-MinReturn         | -14.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 121          |
| train-StdReturn         | 3.96         |
------------------------------------------

 ---------------- Iteration 213 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 213          |
| ItrTime                 | 132          |
| LossAfter               | 0.0072961547 |
| LossBefore              | 0.009429516  |
| Time                    | 4.16e+04     |
| Time-Optimization       | 2.71         |
| Time-SampleProc         | 0.0197       |
| Time-Sampling           | 130          |
| n_timesteps             | 2140000      |
| train-AverageDiscoun... | -12.8        |
| train-AverageReturn     | -10.1        |
| train-EnvExecTime       | 4.08         |
| train-MaxReturn         | 7.8          |
| train-MinReturn         | -16.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 125          |
| train-StdReturn         | 3.97         |
------------------------------------------

 ---------------- Iteration 214 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 214           |
| ItrTime                 | 181           |
| LossAfter               | -0.0059453    |
| LossBefore              | -0.0028518005 |
| Time                    | 4.17e+04      |
| Time-Optimization       | 4.21          |
| Time-SampleProc         | 0.0384        |
| Time-Sampling           | 176           |
| n_timesteps             | 2150000       |
| train-AverageDiscoun... | -6.05         |
| train-AverageReturn     | -6.08         |
| train-EnvExecTime       | 4.56          |
| train-MaxReturn         | 10.2          |
| train-MinReturn         | -15.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 171           |
| train-StdReturn         | 5.61          |
-------------------------------------------

 ---------------- Iteration 215 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 215         |
| ItrTime                 | 127         |
| LossAfter               | 0.010852149 |
| LossBefore              | 0.010155756 |
| Time                    | 4.19e+04    |
| Time-Optimization       | 3.4         |
| Time-SampleProc         | 0.027       |
| Time-Sampling           | 123         |
| n_timesteps             | 2160000     |
| train-AverageDiscoun... | -0.78       |
| train-AverageReturn     | -1.87       |
| train-EnvExecTime       | 4.02        |
| train-MaxReturn         | 8.42        |
| train-MinReturn         | -13.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 119         |
| train-StdReturn         | 4.33        |
-----------------------------------------

 ---------------- Iteration 216 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 216          |
| ItrTime                 | 116          |
| LossAfter               | -0.014692749 |
| LossBefore              | -0.011701503 |
| Time                    | 4.2e+04      |
| Time-Optimization       | 2.88         |
| Time-SampleProc         | 0.0215       |
| Time-Sampling           | 113          |
| n_timesteps             | 2170000      |
| train-AverageDiscoun... | -3.99        |
| train-AverageReturn     | -2.35        |
| train-EnvExecTime       | 3.9          |
| train-MaxReturn         | 10.2         |
| train-MinReturn         | -10.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 109          |
| train-StdReturn         | 4.24         |
------------------------------------------

 ---------------- Iteration 217 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 217          |
| ItrTime                 | 113          |
| LossAfter               | -0.027524384 |
| LossBefore              | -0.015070801 |
| Time                    | 4.21e+04     |
| Time-Optimization       | 2.79         |
| Time-SampleProc         | 0.0697       |
| Time-Sampling           | 110          |
| n_timesteps             | 2180000      |
| train-AverageDiscoun... | -3.25        |
| train-AverageReturn     | -3.17        |
| train-EnvExecTime       | 3.84         |
| train-MaxReturn         | 9.86         |
| train-MinReturn         | -14.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 4.64         |
------------------------------------------

 ---------------- Iteration 218 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 218           |
| ItrTime                 | 112           |
| LossAfter               | -0.01078294   |
| LossBefore              | -0.0142763425 |
| Time                    | 4.22e+04      |
| Time-Optimization       | 2.77          |
| Time-SampleProc         | 0.022         |
| Time-Sampling           | 109           |
| n_timesteps             | 2190000       |
| train-AverageDiscoun... | -13.1         |
| train-AverageReturn     | -10.1         |
| train-EnvExecTime       | 3.79          |
| train-MaxReturn         | 5.87          |
| train-MinReturn         | -14.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 105           |
| train-StdReturn         | 3.2           |
-------------------------------------------

 ---------------- Iteration 219 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 219           |
| ItrTime                 | 113           |
| LossAfter               | -0.0054818755 |
| LossBefore              | -0.0018850341 |
| Time                    | 4.23e+04      |
| Time-Optimization       | 2.85          |
| Time-SampleProc         | 0.0202        |
| Time-Sampling           | 110           |
| n_timesteps             | 2200000       |
| train-AverageDiscoun... | -16.3         |
| train-AverageReturn     | -11.7         |
| train-EnvExecTime       | 3.82          |
| train-MaxReturn         | -4.52         |
| train-MinReturn         | -16.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 106           |
| train-StdReturn         | 1.93          |
-------------------------------------------

 ---------------- Iteration 220 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 220          |
| ItrTime                 | 112          |
| LossAfter               | 0.0075784912 |
| LossBefore              | 0.011192615  |
| Time                    | 4.24e+04     |
| Time-Optimization       | 4.1          |
| Time-SampleProc         | 0.0188       |
| Time-Sampling           | 108          |
| n_timesteps             | 2210000      |
| train-AverageDiscoun... | -15.8        |
| train-AverageReturn     | -11.6        |
| train-EnvExecTime       | 3.77         |
| train-MaxReturn         | -4.51        |
| train-MinReturn         | -15.2        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 104          |
| train-StdReturn         | 2.03         |
------------------------------------------

 ---------------- Iteration 221 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 221          |
| ItrTime                 | 110          |
| LossAfter               | 0.0039832518 |
| LossBefore              | 0.006583569  |
| Time                    | 4.25e+04     |
| Time-Optimization       | 2.78         |
| Time-SampleProc         | 0.0182       |
| Time-Sampling           | 107          |
| n_timesteps             | 2220000      |
| train-AverageDiscoun... | -11.8        |
| train-AverageReturn     | -9.31        |
| train-EnvExecTime       | 3.78         |
| train-MaxReturn         | 4.43         |
| train-MinReturn         | -15.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 103          |
| train-StdReturn         | 3.81         |
------------------------------------------

 ---------------- Iteration 222 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 222          |
| ItrTime                 | 144          |
| LossAfter               | -0.010041187 |
| LossBefore              | -0.008921564 |
| Time                    | 4.27e+04     |
| Time-Optimization       | 5.71         |
| Time-SampleProc         | 0.0278       |
| Time-Sampling           | 139          |
| n_timesteps             | 2230000      |
| train-AverageDiscoun... | -1.23        |
| train-AverageReturn     | -2.77        |
| train-EnvExecTime       | 4.05         |
| train-MaxReturn         | 12           |
| train-MinReturn         | -12.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 134          |
| train-StdReturn         | 4.92         |
------------------------------------------

 ---------------- Iteration 223 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 223         |
| ItrTime                 | 169         |
| LossAfter               | 0.011073181 |
| LossBefore              | 0.013338055 |
| Time                    | 4.29e+04    |
| Time-Optimization       | 2.74        |
| Time-SampleProc         | 0.0279      |
| Time-Sampling           | 167         |
| n_timesteps             | 2240000     |
| train-AverageDiscoun... | -3.39       |
| train-AverageReturn     | -1.76       |
| train-EnvExecTime       | 4.57        |
| train-MaxReturn         | 11.4        |
| train-MinReturn         | -12.1       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 162         |
| train-StdReturn         | 4.5         |
-----------------------------------------

 ---------------- Iteration 224 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 224            |
| ItrTime                 | 117            |
| LossAfter               | -0.00078737794 |
| LossBefore              | 0.008622241    |
| Time                    | 4.3e+04        |
| Time-Optimization       | 2.85           |
| Time-SampleProc         | 0.0477         |
| Time-Sampling           | 114            |
| n_timesteps             | 2250000        |
| train-AverageDiscoun... | -3.1           |
| train-AverageReturn     | -2.12          |
| train-EnvExecTime       | 3.87           |
| train-MaxReturn         | 10.1           |
| train-MinReturn         | -11.4          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 110            |
| train-StdReturn         | 4.38           |
--------------------------------------------

 ---------------- Iteration 225 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 225         |
| ItrTime                 | 114         |
| LossAfter               | 0.004667398 |
| LossBefore              | 0.001177887 |
| Time                    | 4.31e+04    |
| Time-Optimization       | 2.6         |
| Time-SampleProc         | 0.0215      |
| Time-Sampling           | 112         |
| n_timesteps             | 2260000     |
| train-AverageDiscoun... | -10.1       |
| train-AverageReturn     | -8.38       |
| train-EnvExecTime       | 3.86        |
| train-MaxReturn         | 10.5        |
| train-MinReturn         | -16.1       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 108         |
| train-StdReturn         | 4.65        |
-----------------------------------------

 ---------------- Iteration 226 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 226         |
| ItrTime                 | 162         |
| LossAfter               | 0.009964953 |
| LossBefore              | 0.013691297 |
| Time                    | 4.33e+04    |
| Time-Optimization       | 4.11        |
| Time-SampleProc         | 0.0277      |
| Time-Sampling           | 158         |
| n_timesteps             | 2270000     |
| train-AverageDiscoun... | -14.6       |
| train-AverageReturn     | -11.1       |
| train-EnvExecTime       | 4.19        |
| train-MaxReturn         | 9.97        |
| train-MinReturn         | -16.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 153         |
| train-StdReturn         | 3.23        |
-----------------------------------------

 ---------------- Iteration 227 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 227          |
| ItrTime                 | 135          |
| LossAfter               | -0.014529102 |
| LossBefore              | -0.010459412 |
| Time                    | 4.34e+04     |
| Time-Optimization       | 2.87         |
| Time-SampleProc         | 0.023        |
| Time-Sampling           | 132          |
| n_timesteps             | 2280000      |
| train-AverageDiscoun... | -11.4        |
| train-AverageReturn     | -9.06        |
| train-EnvExecTime       | 4.14         |
| train-MaxReturn         | 7.64         |
| train-MinReturn         | -15.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 127          |
| train-StdReturn         | 4.04         |
------------------------------------------

 ---------------- Iteration 228 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 228          |
| ItrTime                 | 117          |
| LossAfter               | 0.008800879  |
| LossBefore              | 0.0071086977 |
| Time                    | 4.35e+04     |
| Time-Optimization       | 2.55         |
| Time-SampleProc         | 0.0273       |
| Time-Sampling           | 115          |
| n_timesteps             | 2290000      |
| train-AverageDiscoun... | -1.21        |
| train-AverageReturn     | -1.87        |
| train-EnvExecTime       | 3.9          |
| train-MaxReturn         | 8.35         |
| train-MinReturn         | -11.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 110          |
| train-StdReturn         | 4.37         |
------------------------------------------

 ---------------- Iteration 229 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 229          |
| ItrTime                 | 117          |
| LossAfter               | 0.0053494326 |
| LossBefore              | 0.008627581  |
| Time                    | 4.36e+04     |
| Time-Optimization       | 2.72         |
| Time-SampleProc         | 0.0217       |
| Time-Sampling           | 114          |
| n_timesteps             | 2300000      |
| train-AverageDiscoun... | -4.16        |
| train-AverageReturn     | -1.86        |
| train-EnvExecTime       | 3.94         |
| train-MaxReturn         | 6.92         |
| train-MinReturn         | -10.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 110          |
| train-StdReturn         | 3.6          |
------------------------------------------

 ---------------- Iteration 230 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 230          |
| ItrTime                 | 119          |
| LossAfter               | -0.023048596 |
| LossBefore              | -0.015922619 |
| Time                    | 4.37e+04     |
| Time-Optimization       | 2.81         |
| Time-SampleProc         | 0.0286       |
| Time-Sampling           | 116          |
| n_timesteps             | 2310000      |
| train-AverageDiscoun... | -2.33        |
| train-AverageReturn     | -2.55        |
| train-EnvExecTime       | 3.91         |
| train-MaxReturn         | 10.1         |
| train-MinReturn         | -14.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 111          |
| train-StdReturn         | 4.48         |
------------------------------------------

 ---------------- Iteration 231 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 231          |
| ItrTime                 | 121          |
| LossAfter               | -0.008554492 |
| LossBefore              | -0.010641748 |
| Time                    | 4.39e+04     |
| Time-Optimization       | 2.75         |
| Time-SampleProc         | 0.0205       |
| Time-Sampling           | 118          |
| n_timesteps             | 2320000      |
| train-AverageDiscoun... | -13          |
| train-AverageReturn     | -9.95        |
| train-EnvExecTime       | 4.01         |
| train-MaxReturn         | 1.56         |
| train-MinReturn         | -15          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 114          |
| train-StdReturn         | 3.32         |
------------------------------------------

 ---------------- Iteration 232 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 232         |
| ItrTime                 | 117         |
| LossAfter               | 0.001875653 |
| LossBefore              | 0.005511615 |
| Time                    | 4.4e+04     |
| Time-Optimization       | 2.67        |
| Time-SampleProc         | 0.0305      |
| Time-Sampling           | 115         |
| n_timesteps             | 2330000     |
| train-AverageDiscoun... | -15.2       |
| train-AverageReturn     | -11.2       |
| train-EnvExecTime       | 3.9         |
| train-MaxReturn         | -1.91       |
| train-MinReturn         | -16         |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 110         |
| train-StdReturn         | 2.42        |
-----------------------------------------

 ---------------- Iteration 233 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 233         |
| ItrTime                 | 119         |
| LossAfter               | 0.017027875 |
| LossBefore              | 0.01935382  |
| Time                    | 4.41e+04    |
| Time-Optimization       | 2.83        |
| Time-SampleProc         | 0.0186      |
| Time-Sampling           | 116         |
| n_timesteps             | 2340000     |
| train-AverageDiscoun... | -13.7       |
| train-AverageReturn     | -10.6       |
| train-EnvExecTime       | 3.94        |
| train-MaxReturn         | 0.914       |
| train-MinReturn         | -15.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 112         |
| train-StdReturn         | 3.1         |
-----------------------------------------

 ---------------- Iteration 234 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 234          |
| ItrTime                 | 119          |
| LossAfter               | 0.0027845216 |
| LossBefore              | 0.0068758666 |
| Time                    | 4.42e+04     |
| Time-Optimization       | 7.88         |
| Time-SampleProc         | 0.0271       |
| Time-Sampling           | 111          |
| n_timesteps             | 2350000      |
| train-AverageDiscoun... | -5.78        |
| train-AverageReturn     | -5.54        |
| train-EnvExecTime       | 3.98         |
| train-MaxReturn         | 8.89         |
| train-MinReturn         | -13.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 106          |
| train-StdReturn         | 5.54         |
------------------------------------------

 ---------------- Iteration 235 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 235         |
| ItrTime                 | 200         |
| LossAfter               | 0.008932892 |
| LossBefore              | 0.009671472 |
| Time                    | 4.44e+04    |
| Time-Optimization       | 3.63        |
| Time-SampleProc         | 0.0312      |
| Time-Sampling           | 196         |
| n_timesteps             | 2360000     |
| train-AverageDiscoun... | -4.01       |
| train-AverageReturn     | -2.02       |
| train-EnvExecTime       | 4.53        |
| train-MaxReturn         | 6.27        |
| train-MinReturn         | -11.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 191         |
| train-StdReturn         | 3.5         |
-----------------------------------------

 ---------------- Iteration 236 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 236           |
| ItrTime                 | 133           |
| LossAfter               | -0.0061422484 |
| LossBefore              | 0.004703479   |
| Time                    | 4.45e+04      |
| Time-Optimization       | 2.7           |
| Time-SampleProc         | 0.0298        |
| Time-Sampling           | 130           |
| n_timesteps             | 2370000       |
| train-AverageDiscoun... | -3.22         |
| train-AverageReturn     | -2.02         |
| train-EnvExecTime       | 4.26          |
| train-MaxReturn         | 7.46          |
| train-MinReturn         | -12           |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 126           |
| train-StdReturn         | 3.95          |
-------------------------------------------

 ---------------- Iteration 237 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 237          |
| ItrTime                 | 128          |
| LossAfter               | 0.0086612245 |
| LossBefore              | 0.0050630067 |
| Time                    | 4.47e+04     |
| Time-Optimization       | 3.98         |
| Time-SampleProc         | 0.0235       |
| Time-Sampling           | 124          |
| n_timesteps             | 2380000      |
| train-AverageDiscoun... | -10.1        |
| train-AverageReturn     | -8.22        |
| train-EnvExecTime       | 3.9          |
| train-MaxReturn         | 5.91         |
| train-MinReturn         | -15.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 120          |
| train-StdReturn         | 4.68         |
------------------------------------------

 ---------------- Iteration 238 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 238         |
| ItrTime                 | 116         |
| LossAfter               | 0.004933508 |
| LossBefore              | 0.009856958 |
| Time                    | 4.48e+04    |
| Time-Optimization       | 2.71        |
| Time-SampleProc         | 0.022       |
| Time-Sampling           | 113         |
| n_timesteps             | 2390000     |
| train-AverageDiscoun... | -13.5       |
| train-AverageReturn     | -10.3       |
| train-EnvExecTime       | 3.88        |
| train-MaxReturn         | 8.19        |
| train-MinReturn         | -16.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 109         |
| train-StdReturn         | 3.56        |
-----------------------------------------

 ---------------- Iteration 239 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 239           |
| ItrTime                 | 124           |
| LossAfter               | -0.021633014  |
| LossBefore              | -0.0126759885 |
| Time                    | 4.49e+04      |
| Time-Optimization       | 2.63          |
| Time-SampleProc         | 0.0194        |
| Time-Sampling           | 121           |
| n_timesteps             | 2400000       |
| train-AverageDiscoun... | -6.38         |
| train-AverageReturn     | -6.3          |
| train-EnvExecTime       | 3.9           |
| train-MaxReturn         | 7.55          |
| train-MinReturn         | -14.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 117           |
| train-StdReturn         | 5.34          |
-------------------------------------------

 ---------------- Iteration 240 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 240            |
| ItrTime                 | 130            |
| LossAfter               | -0.00029616698 |
| LossBefore              | -0.0027921142  |
| Time                    | 4.5e+04        |
| Time-Optimization       | 3.42           |
| Time-SampleProc         | 0.0219         |
| Time-Sampling           | 127            |
| n_timesteps             | 2410000        |
| train-AverageDiscoun... | -4.49          |
| train-AverageReturn     | -2.03          |
| train-EnvExecTime       | 3.98           |
| train-MaxReturn         | 6.75           |
| train-MinReturn         | -11.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 122            |
| train-StdReturn         | 3.89           |
--------------------------------------------

 ---------------- Iteration 241 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 241           |
| ItrTime                 | 124           |
| LossAfter               | -0.0019491776 |
| LossBefore              | 0.013413237   |
| Time                    | 4.52e+04      |
| Time-Optimization       | 3.58          |
| Time-SampleProc         | 0.0644        |
| Time-Sampling           | 120           |
| n_timesteps             | 2420000       |
| train-AverageDiscoun... | -6.12         |
| train-AverageReturn     | -2.29         |
| train-EnvExecTime       | 3.89          |
| train-MaxReturn         | 10.1          |
| train-MinReturn         | -9.51         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 116           |
| train-StdReturn         | 3.59          |
-------------------------------------------

 ---------------- Iteration 242 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 242           |
| ItrTime                 | 423           |
| LossAfter               | 0.0018133301  |
| LossBefore              | -0.0023954955 |
| Time                    | 4.56e+04      |
| Time-Optimization       | 5.3           |
| Time-SampleProc         | 0.0496        |
| Time-Sampling           | 418           |
| n_timesteps             | 2430000       |
| train-AverageDiscoun... | -4.6          |
| train-AverageReturn     | -5            |
| train-EnvExecTime       | 4.33          |
| train-MaxReturn         | 7.06          |
| train-MinReturn         | -12.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 413           |
| train-StdReturn         | 5.37          |
-------------------------------------------

 ---------------- Iteration 243 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 243          |
| ItrTime                 | 2.13e+03     |
| LossAfter               | -0.013046417 |
| LossBefore              | -0.008588306 |
| Time                    | 4.77e+04     |
| Time-Optimization       | 4.04         |
| Time-SampleProc         | 0.0604       |
| Time-Sampling           | 2.13e+03     |
| n_timesteps             | 2440000      |
| train-AverageDiscoun... | -13.3        |
| train-AverageReturn     | -10.2        |
| train-EnvExecTime       | 5.37         |
| train-MaxReturn         | -0.0381      |
| train-MinReturn         | -15          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 2.12e+03     |
| train-StdReturn         | 2.85         |
------------------------------------------

 ---------------- Iteration 244 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 244          |
| ItrTime                 | 154          |
| LossAfter               | 0.0049715578 |
| LossBefore              | 0.009111036  |
| Time                    | 4.79e+04     |
| Time-Optimization       | 4.02         |
| Time-SampleProc         | 0.0397       |
| Time-Sampling           | 149          |
| n_timesteps             | 2450000      |
| train-AverageDiscoun... | -8.32        |
| train-AverageReturn     | -7.93        |
| train-EnvExecTime       | 5.34         |
| train-MaxReturn         | 13.5         |
| train-MinReturn         | -15.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 144          |
| train-StdReturn         | 5.03         |
------------------------------------------

 ---------------- Iteration 245 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 245          |
| ItrTime                 | 146          |
| LossAfter               | 0.0059160767 |
| LossBefore              | 0.005747229  |
| Time                    | 4.8e+04      |
| Time-Optimization       | 5.16         |
| Time-SampleProc         | 0.0802       |
| Time-Sampling           | 141          |
| n_timesteps             | 2460000      |
| train-AverageDiscoun... | -1.62        |
| train-AverageReturn     | -2.57        |
| train-EnvExecTime       | 5.31         |
| train-MaxReturn         | 11.2         |
| train-MinReturn         | -13.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 135          |
| train-StdReturn         | 5.36         |
------------------------------------------

 ---------------- Iteration 246 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 246          |
| ItrTime                 | 152          |
| LossAfter               | 0.0021371339 |
| LossBefore              | 0.008772864  |
| Time                    | 4.82e+04     |
| Time-Optimization       | 4.36         |
| Time-SampleProc         | 0.033        |
| Time-Sampling           | 148          |
| n_timesteps             | 2470000      |
| train-AverageDiscoun... | -6.46        |
| train-AverageReturn     | -2.64        |
| train-EnvExecTime       | 5.38         |
| train-MaxReturn         | 6.41         |
| train-MinReturn         | -10.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 142          |
| train-StdReturn         | 3.57         |
------------------------------------------

 ---------------- Iteration 247 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 247          |
| ItrTime                 | 150          |
| LossAfter               | -0.011311462 |
| LossBefore              | 0.0019888794 |
| Time                    | 4.83e+04     |
| Time-Optimization       | 4.13         |
| Time-SampleProc         | 0.0283       |
| Time-Sampling           | 146          |
| n_timesteps             | 2480000      |
| train-AverageDiscoun... | -3.66        |
| train-AverageReturn     | -2.34        |
| train-EnvExecTime       | 5.37         |
| train-MaxReturn         | 8.73         |
| train-MinReturn         | -12.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 140          |
| train-StdReturn         | 4.62         |
------------------------------------------

 ---------------- Iteration 248 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 248          |
| ItrTime                 | 153          |
| LossAfter               | 0.0043494627 |
| LossBefore              | -0.000439917 |
| Time                    | 4.85e+04     |
| Time-Optimization       | 4.19         |
| Time-SampleProc         | 0.0473       |
| Time-Sampling           | 149          |
| n_timesteps             | 2490000      |
| train-AverageDiscoun... | -12.3        |
| train-AverageReturn     | -9.7         |
| train-EnvExecTime       | 5.37         |
| train-MaxReturn         | 7.26         |
| train-MinReturn         | -16.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 143          |
| train-StdReturn         | 4.2          |
------------------------------------------

 ---------------- Iteration 249 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 249           |
| ItrTime                 | 176           |
| LossAfter               | -0.005241205  |
| LossBefore              | -0.0037239501 |
| Time                    | 4.87e+04      |
| Time-Optimization       | 6.14          |
| Time-SampleProc         | 0.169         |
| Time-Sampling           | 170           |
| n_timesteps             | 2500000       |
| train-AverageDiscoun... | -16.4         |
| train-AverageReturn     | -11.9         |
| train-EnvExecTime       | 6.06          |
| train-MaxReturn         | -4.99         |
| train-MinReturn         | -16.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 163           |
| train-StdReturn         | 2.21          |
-------------------------------------------

 ---------------- Iteration 250 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
----------------------------------------
| Itr                     | 250        |
| ItrTime                 | 247        |
| LossAfter               | 0.01759364 |
| LossBefore              | 0.01780932 |
| Time                    | 4.89e+04   |
| Time-Optimization       | 6.85       |
| Time-SampleProc         | 0.12       |
| Time-Sampling           | 240        |
| n_timesteps             | 2510000    |
| train-AverageDiscoun... | -16        |
| train-AverageReturn     | -11.7      |
| train-EnvExecTime       | 8.94       |
| train-MaxReturn         | -3.09      |
| train-MinReturn         | -17.2      |
| train-NumTrajs          | 100        |
| train-PolicyExecTime    | 230        |
| train-StdReturn         | 2.19       |
----------------------------------------

 ---------------- Iteration 251 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 251           |
| ItrTime                 | 214           |
| LossAfter               | -0.01029729   |
| LossBefore              | -0.0056256712 |
| Time                    | 4.91e+04      |
| Time-Optimization       | 5.93          |
| Time-SampleProc         | 0.183         |
| Time-Sampling           | 207           |
| n_timesteps             | 2520000       |
| train-AverageDiscoun... | -14.4         |
| train-AverageReturn     | -11           |
| train-EnvExecTime       | 8.32          |
| train-MaxReturn         | 2.55          |
| train-MinReturn         | -15.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 198           |
| train-StdReturn         | 3.27          |
-------------------------------------------

 ---------------- Iteration 252 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 252           |
| ItrTime                 | 223           |
| LossAfter               | -0.022933789  |
| LossBefore              | -0.0130653195 |
| Time                    | 4.93e+04      |
| Time-Optimization       | 7.51          |
| Time-SampleProc         | 0.2           |
| Time-Sampling           | 215           |
| n_timesteps             | 2530000       |
| train-AverageDiscoun... | -5.96         |
| train-AverageReturn     | -5.83         |
| train-EnvExecTime       | 8.62          |
| train-MaxReturn         | 8.77          |
| train-MinReturn         | -13.8         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 206           |
| train-StdReturn         | 5.71          |
-------------------------------------------

 ---------------- Iteration 253 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 253           |
| ItrTime                 | 241           |
| LossAfter               | -0.0013799865 |
| LossBefore              | -0.0033399903 |
| Time                    | 4.96e+04      |
| Time-Optimization       | 7.92          |
| Time-SampleProc         | 0.198         |
| Time-Sampling           | 233           |
| n_timesteps             | 2540000       |
| train-AverageDiscoun... | -6.76         |
| train-AverageReturn     | -2.85         |
| train-EnvExecTime       | 8.96          |
| train-MaxReturn         | 8.65          |
| train-MinReturn         | -11.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 223           |
| train-StdReturn         | 3.92          |
-------------------------------------------

 ---------------- Iteration 254 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 254           |
| ItrTime                 | 246           |
| LossAfter               | -0.0027911866 |
| LossBefore              | 0.0074317628  |
| Time                    | 4.98e+04      |
| Time-Optimization       | 7.69          |
| Time-SampleProc         | 0.0742        |
| Time-Sampling           | 238           |
| n_timesteps             | 2550000       |
| train-AverageDiscoun... | -6.85         |
| train-AverageReturn     | -2.61         |
| train-EnvExecTime       | 8.82          |
| train-MaxReturn         | 10.2          |
| train-MinReturn         | -12.9         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 228           |
| train-StdReturn         | 3.73          |
-------------------------------------------

 ---------------- Iteration 255 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 255          |
| ItrTime                 | 249          |
| LossAfter               | 0.010669252  |
| LossBefore              | 0.0084317215 |
| Time                    | 5.01e+04     |
| Time-Optimization       | 10           |
| Time-SampleProc         | 0.0537       |
| Time-Sampling           | 239          |
| n_timesteps             | 2560000      |
| train-AverageDiscoun... | -2.41        |
| train-AverageReturn     | -3.48        |
| train-EnvExecTime       | 8.91         |
| train-MaxReturn         | 8.75         |
| train-MinReturn         | -15.3        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 230          |
| train-StdReturn         | 5.51         |
------------------------------------------

 ---------------- Iteration 256 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 256           |
| ItrTime                 | 261           |
| LossAfter               | -0.0051523927 |
| LossBefore              | -0.004977954  |
| Time                    | 5.03e+04      |
| Time-Optimization       | 7.8           |
| Time-SampleProc         | 0.0792        |
| Time-Sampling           | 253           |
| n_timesteps             | 2570000       |
| train-AverageDiscoun... | -11.1         |
| train-AverageReturn     | -8.95         |
| train-EnvExecTime       | 9.01          |
| train-MaxReturn         | 5.91          |
| train-MinReturn         | -14.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 243           |
| train-StdReturn         | 4.08          |
-------------------------------------------

 ---------------- Iteration 257 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 257           |
| ItrTime                 | 255           |
| LossAfter               | -0.020587452  |
| LossBefore              | -0.0083093075 |
| Time                    | 5.06e+04      |
| Time-Optimization       | 6.07          |
| Time-SampleProc         | 0.076         |
| Time-Sampling           | 249           |
| n_timesteps             | 2580000       |
| train-AverageDiscoun... | -11.3         |
| train-AverageReturn     | -9.11         |
| train-EnvExecTime       | 9.11          |
| train-MaxReturn         | 3.1           |
| train-MinReturn         | -15.7         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 239           |
| train-StdReturn         | 3.97          |
-------------------------------------------

 ---------------- Iteration 258 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 258           |
| ItrTime                 | 225           |
| LossAfter               | 0.0012029083  |
| LossBefore              | -0.0027795746 |
| Time                    | 5.08e+04      |
| Time-Optimization       | 6.26          |
| Time-SampleProc         | 0.0712        |
| Time-Sampling           | 218           |
| n_timesteps             | 2590000       |
| train-AverageDiscoun... | -1.4          |
| train-AverageReturn     | -2.01         |
| train-EnvExecTime       | 8.65          |
| train-MaxReturn         | 10.2          |
| train-MinReturn         | -11.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 209           |
| train-StdReturn         | 4.29          |
-------------------------------------------

 ---------------- Iteration 259 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 259           |
| ItrTime                 | 261           |
| LossAfter               | -0.008790126  |
| LossBefore              | -0.0016313446 |
| Time                    | 5.11e+04      |
| Time-Optimization       | 12.6          |
| Time-SampleProc         | 0.0588        |
| Time-Sampling           | 249           |
| n_timesteps             | 2600000       |
| train-AverageDiscoun... | -5.78         |
| train-AverageReturn     | -2.6          |
| train-EnvExecTime       | 9.17          |
| train-MaxReturn         | 10.3          |
| train-MinReturn         | -12.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 238           |
| train-StdReturn         | 4.28          |
-------------------------------------------

 ---------------- Iteration 260 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 260           |
| ItrTime                 | 283           |
| LossAfter               | 0.0011515991  |
| LossBefore              | -0.0005758911 |
| Time                    | 5.14e+04      |
| Time-Optimization       | 5.79          |
| Time-SampleProc         | 0.0538        |
| Time-Sampling           | 277           |
| n_timesteps             | 2610000       |
| train-AverageDiscoun... | -2.73         |
| train-AverageReturn     | -2.85         |
| train-EnvExecTime       | 9.86          |
| train-MaxReturn         | 7.85          |
| train-MinReturn         | -13.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 266           |
| train-StdReturn         | 4.74          |
-------------------------------------------

 ---------------- Iteration 261 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 261          |
| ItrTime                 | 245          |
| LossAfter               | 0.0077328733 |
| LossBefore              | 0.013323535  |
| Time                    | 5.16e+04     |
| Time-Optimization       | 5.92         |
| Time-SampleProc         | 0.218        |
| Time-Sampling           | 239          |
| n_timesteps             | 2620000      |
| train-AverageDiscoun... | -9.42        |
| train-AverageReturn     | -7.71        |
| train-EnvExecTime       | 9.59         |
| train-MaxReturn         | 5.54         |
| train-MinReturn         | -15.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 228          |
| train-StdReturn         | 4.3          |
------------------------------------------

 ---------------- Iteration 262 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 262            |
| ItrTime                 | 239            |
| LossAfter               | -0.0038841919  |
| LossBefore              | -0.00040321655 |
| Time                    | 5.18e+04       |
| Time-Optimization       | 8.27           |
| Time-SampleProc         | 0.115          |
| Time-Sampling           | 231            |
| n_timesteps             | 2630000        |
| train-AverageDiscoun... | -3.2           |
| train-AverageReturn     | -4.07          |
| train-EnvExecTime       | 9.29           |
| train-MaxReturn         | 10.2           |
| train-MinReturn         | -13.3          |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 220            |
| train-StdReturn         | 5.32           |
--------------------------------------------

 ---------------- Iteration 263 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 263          |
| ItrTime                 | 233          |
| LossAfter               | -0.01371409  |
| LossBefore              | -0.014488852 |
| Time                    | 5.21e+04     |
| Time-Optimization       | 6.81         |
| Time-SampleProc         | 0.0592       |
| Time-Sampling           | 226          |
| n_timesteps             | 2640000      |
| train-AverageDiscoun... | -7.27        |
| train-AverageReturn     | -3.16        |
| train-EnvExecTime       | 9.1          |
| train-MaxReturn         | 6.15         |
| train-MinReturn         | -11.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 216          |
| train-StdReturn         | 4.12         |
------------------------------------------

 ---------------- Iteration 264 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 264          |
| ItrTime                 | 246          |
| LossAfter               | -0.02016361  |
| LossBefore              | -0.007159705 |
| Time                    | 5.23e+04     |
| Time-Optimization       | 7.45         |
| Time-SampleProc         | 0.133        |
| Time-Sampling           | 238          |
| n_timesteps             | 2650000      |
| train-AverageDiscoun... | -6.46        |
| train-AverageReturn     | -2.5         |
| train-EnvExecTime       | 9.31         |
| train-MaxReturn         | 9.44         |
| train-MinReturn         | -11.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 228          |
| train-StdReturn         | 3.96         |
------------------------------------------

 ---------------- Iteration 265 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 265           |
| ItrTime                 | 225           |
| LossAfter               | -0.00030457   |
| LossBefore              | -0.0032893554 |
| Time                    | 5.26e+04      |
| Time-Optimization       | 6.6           |
| Time-SampleProc         | 0.0688        |
| Time-Sampling           | 218           |
| n_timesteps             | 2660000       |
| train-AverageDiscoun... | -3.02         |
| train-AverageReturn     | -4.09         |
| train-EnvExecTime       | 8.72          |
| train-MaxReturn         | 7.7           |
| train-MinReturn         | -15.4         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 209           |
| train-StdReturn         | 5.34          |
-------------------------------------------

 ---------------- Iteration 266 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 266         |
| ItrTime                 | 218         |
| LossAfter               | 0.013448633 |
| LossBefore              | 0.013562659 |
| Time                    | 5.28e+04    |
| Time-Optimization       | 9           |
| Time-SampleProc         | 0.0662      |
| Time-Sampling           | 209         |
| n_timesteps             | 2670000     |
| train-AverageDiscoun... | -13.2       |
| train-AverageReturn     | -10.1       |
| train-EnvExecTime       | 8.51        |
| train-MaxReturn         | 5.24        |
| train-MinReturn         | -15.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 200         |
| train-StdReturn         | 3.2         |
-----------------------------------------

 ---------------- Iteration 267 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 267          |
| ItrTime                 | 226          |
| LossAfter               | 0.0034781785 |
| LossBefore              | 0.008652382  |
| Time                    | 5.3e+04      |
| Time-Optimization       | 6.32         |
| Time-SampleProc         | 0.0432       |
| Time-Sampling           | 220          |
| n_timesteps             | 2680000      |
| train-AverageDiscoun... | -12.4        |
| train-AverageReturn     | -9.93        |
| train-EnvExecTime       | 8.52         |
| train-MaxReturn         | 4.46         |
| train-MinReturn         | -16.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 210          |
| train-StdReturn         | 3.64         |
------------------------------------------

 ---------------- Iteration 268 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 268          |
| ItrTime                 | 231          |
| LossAfter               | -0.007973217 |
| LossBefore              | -0.002267241 |
| Time                    | 5.32e+04     |
| Time-Optimization       | 6.4          |
| Time-SampleProc         | 0.147        |
| Time-Sampling           | 225          |
| n_timesteps             | 2690000      |
| train-AverageDiscoun... | -2.23        |
| train-AverageReturn     | -4.39        |
| train-EnvExecTime       | 8.44         |
| train-MaxReturn         | 9.23         |
| train-MinReturn         | -14.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 215          |
| train-StdReturn         | 5.36         |
------------------------------------------

 ---------------- Iteration 269 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 269          |
| ItrTime                 | 227          |
| LossAfter               | 0.003970801  |
| LossBefore              | 0.0030954955 |
| Time                    | 5.35e+04     |
| Time-Optimization       | 6.4          |
| Time-SampleProc         | 0.0516       |
| Time-Sampling           | 221          |
| n_timesteps             | 2700000      |
| train-AverageDiscoun... | -5.6         |
| train-AverageReturn     | -2.3         |
| train-EnvExecTime       | 8.62         |
| train-MaxReturn         | 8.99         |
| train-MinReturn         | -10.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 211          |
| train-StdReturn         | 3.72         |
------------------------------------------

 ---------------- Iteration 270 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 270         |
| ItrTime                 | 234         |
| LossAfter               | 0.005654935 |
| LossBefore              | 0.010724359 |
| Time                    | 5.37e+04    |
| Time-Optimization       | 7.1         |
| Time-SampleProc         | 0.0581      |
| Time-Sampling           | 226         |
| n_timesteps             | 2710000     |
| train-AverageDiscoun... | -7.13       |
| train-AverageReturn     | -2.65       |
| train-EnvExecTime       | 8.55        |
| train-MaxReturn         | 7.73        |
| train-MinReturn         | -11.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 217         |
| train-StdReturn         | 3.74        |
-----------------------------------------

 ---------------- Iteration 271 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 271          |
| ItrTime                 | 240          |
| LossAfter               | -0.014557556 |
| LossBefore              | -0.009665332 |
| Time                    | 5.39e+04     |
| Time-Optimization       | 6.76         |
| Time-SampleProc         | 0.0903       |
| Time-Sampling           | 233          |
| n_timesteps             | 2720000      |
| train-AverageDiscoun... | -3.18        |
| train-AverageReturn     | -2.19        |
| train-EnvExecTime       | 8.75         |
| train-MaxReturn         | 9.06         |
| train-MinReturn         | -13.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 224          |
| train-StdReturn         | 4.66         |
------------------------------------------

 ---------------- Iteration 272 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 272          |
| ItrTime                 | 296          |
| LossAfter               | 0.004781372  |
| LossBefore              | 0.0035911498 |
| Time                    | 5.42e+04     |
| Time-Optimization       | 9.34         |
| Time-SampleProc         | 0.0941       |
| Time-Sampling           | 286          |
| n_timesteps             | 2730000      |
| train-AverageDiscoun... | -10.5        |
| train-AverageReturn     | -8.73        |
| train-EnvExecTime       | 8.74         |
| train-MaxReturn         | 5.01         |
| train-MinReturn         | -14.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 276          |
| train-StdReturn         | 4.31         |
------------------------------------------

 ---------------- Iteration 273 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 273          |
| ItrTime                 | 229          |
| LossAfter               | 0.0025446778 |
| LossBefore              | 0.012827368  |
| Time                    | 5.45e+04     |
| Time-Optimization       | 6.82         |
| Time-SampleProc         | 0.0564       |
| Time-Sampling           | 222          |
| n_timesteps             | 2740000      |
| train-AverageDiscoun... | -13.3        |
| train-AverageReturn     | -10.4        |
| train-EnvExecTime       | 8.58         |
| train-MaxReturn         | 0.51         |
| train-MinReturn         | -15.7        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 213          |
| train-StdReturn         | 3.07         |
------------------------------------------

 ---------------- Iteration 274 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 274          |
| ItrTime                 | 310          |
| LossAfter               | 0.009204178  |
| LossBefore              | 0.0080519775 |
| Time                    | 5.48e+04     |
| Time-Optimization       | 10.7         |
| Time-SampleProc         | 0.117        |
| Time-Sampling           | 299          |
| n_timesteps             | 2750000      |
| train-AverageDiscoun... | -2.07        |
| train-AverageReturn     | -2.63        |
| train-EnvExecTime       | 11.4         |
| train-MaxReturn         | 7.42         |
| train-MinReturn         | -12.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 286          |
| train-StdReturn         | 4.79         |
------------------------------------------

 ---------------- Iteration 275 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 275          |
| ItrTime                 | 196          |
| LossAfter               | 0.0017759094 |
| LossBefore              | 0.0055682175 |
| Time                    | 5.5e+04      |
| Time-Optimization       | 5.98         |
| Time-SampleProc         | 0.0788       |
| Time-Sampling           | 190          |
| n_timesteps             | 2760000      |
| train-AverageDiscoun... | -9.05        |
| train-AverageReturn     | -3.89        |
| train-EnvExecTime       | 9.15         |
| train-MaxReturn         | 10.4         |
| train-MinReturn         | -12.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 180          |
| train-StdReturn         | 3.63         |
------------------------------------------

 ---------------- Iteration 276 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 276          |
| ItrTime                 | 161          |
| LossAfter               | -0.019215332 |
| LossBefore              | 0.003919812  |
| Time                    | 5.51e+04     |
| Time-Optimization       | 5.31         |
| Time-SampleProc         | 0.0619       |
| Time-Sampling           | 156          |
| n_timesteps             | 2770000      |
| train-AverageDiscoun... | -5.46        |
| train-AverageReturn     | -2.5         |
| train-EnvExecTime       | 9.11         |
| train-MaxReturn         | 8.18         |
| train-MinReturn         | -11.9        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 146          |
| train-StdReturn         | 4.44         |
------------------------------------------

 ---------------- Iteration 277 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 277         |
| ItrTime                 | 146         |
| LossAfter               | 0.020755969 |
| LossBefore              | 0.014000476 |
| Time                    | 5.53e+04    |
| Time-Optimization       | 5.14        |
| Time-SampleProc         | 0.0539      |
| Time-Sampling           | 141         |
| n_timesteps             | 2780000     |
| train-AverageDiscoun... | -12.6       |
| train-AverageReturn     | -9.91       |
| train-EnvExecTime       | 8.85        |
| train-MaxReturn         | 2.32        |
| train-MinReturn         | -14.9       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 131         |
| train-StdReturn         | 3.88        |
-----------------------------------------

 ---------------- Iteration 278 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 278           |
| ItrTime                 | 140           |
| LossAfter               | -0.0022354736 |
| LossBefore              | -0.0027345612 |
| Time                    | 5.54e+04      |
| Time-Optimization       | 5.56          |
| Time-SampleProc         | 0.0562        |
| Time-Sampling           | 135           |
| n_timesteps             | 2790000       |
| train-AverageDiscoun... | -17.4         |
| train-AverageReturn     | -12.5         |
| train-EnvExecTime       | 8.55          |
| train-MaxReturn         | -8.8          |
| train-MinReturn         | -16.3         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 125           |
| train-StdReturn         | 1.82          |
-------------------------------------------

 ---------------- Iteration 279 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
--------------------------------------------
| Itr                     | 279            |
| ItrTime                 | 148            |
| LossAfter               | -0.00069902954 |
| LossBefore              | -0.000575058   |
| Time                    | 5.56e+04       |
| Time-Optimization       | 5.37           |
| Time-SampleProc         | 0.0788         |
| Time-Sampling           | 143            |
| n_timesteps             | 2800000        |
| train-AverageDiscoun... | -17.5          |
| train-AverageReturn     | -12.5          |
| train-EnvExecTime       | 8.67           |
| train-MaxReturn         | -6.85          |
| train-MinReturn         | -16            |
| train-NumTrajs          | 100            |
| train-PolicyExecTime    | 133            |
| train-StdReturn         | 1.89           |
--------------------------------------------

 ---------------- Iteration 280 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 280          |
| ItrTime                 | 138          |
| LossAfter               | -0.008571045 |
| LossBefore              | -0.005920648 |
| Time                    | 5.57e+04     |
| Time-Optimization       | 6.08         |
| Time-SampleProc         | 0.0703       |
| Time-Sampling           | 132          |
| n_timesteps             | 2810000      |
| train-AverageDiscoun... | -17.5        |
| train-AverageReturn     | -12.6        |
| train-EnvExecTime       | 8.44         |
| train-MaxReturn         | -7.04        |
| train-MinReturn         | -16.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 123          |
| train-StdReturn         | 1.79         |
------------------------------------------

 ---------------- Iteration 281 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 281           |
| ItrTime                 | 141           |
| LossAfter               | -0.0033699372 |
| LossBefore              | -0.0039493684 |
| Time                    | 5.58e+04      |
| Time-Optimization       | 5.58          |
| Time-SampleProc         | 0.0468        |
| Time-Sampling           | 136           |
| n_timesteps             | 2820000       |
| train-AverageDiscoun... | -16.7         |
| train-AverageReturn     | -12           |
| train-EnvExecTime       | 8.59          |
| train-MaxReturn         | -6.19         |
| train-MinReturn         | -16.2         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 126           |
| train-StdReturn         | 1.83          |
-------------------------------------------

 ---------------- Iteration 282 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 282          |
| ItrTime                 | 155          |
| LossAfter               | -0.022918189 |
| LossBefore              | -0.021627784 |
| Time                    | 5.6e+04      |
| Time-Optimization       | 5.73         |
| Time-SampleProc         | 0.0511       |
| Time-Sampling           | 149          |
| n_timesteps             | 2830000      |
| train-AverageDiscoun... | -15.7        |
| train-AverageReturn     | -11.6        |
| train-EnvExecTime       | 8.86         |
| train-MaxReturn         | -5.87        |
| train-MinReturn         | -17.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 139          |
| train-StdReturn         | 2.18         |
------------------------------------------

 ---------------- Iteration 283 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 283          |
| ItrTime                 | 147          |
| LossAfter               | -0.011315857 |
| LossBefore              | -0.011606616 |
| Time                    | 5.61e+04     |
| Time-Optimization       | 6.86         |
| Time-SampleProc         | 0.05         |
| Time-Sampling           | 140          |
| n_timesteps             | 2840000      |
| train-AverageDiscoun... | -15.2        |
| train-AverageReturn     | -11.2        |
| train-EnvExecTime       | 8.81         |
| train-MaxReturn         | 0.863        |
| train-MinReturn         | -16.4        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 130          |
| train-StdReturn         | 2.27         |
------------------------------------------

 ---------------- Iteration 284 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 284         |
| ItrTime                 | 139         |
| LossAfter               | 0.019383123 |
| LossBefore              | 0.023679966 |
| Time                    | 5.63e+04    |
| Time-Optimization       | 5.25        |
| Time-SampleProc         | 0.0517      |
| Time-Sampling           | 134         |
| n_timesteps             | 2850000     |
| train-AverageDiscoun... | -14.7       |
| train-AverageReturn     | -11         |
| train-EnvExecTime       | 8.45        |
| train-MaxReturn         | 3.5         |
| train-MinReturn         | -15.4       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 124         |
| train-StdReturn         | 3.1         |
-----------------------------------------

 ---------------- Iteration 285 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 285          |
| ItrTime                 | 143          |
| LossAfter               | -0.033490714 |
| LossBefore              | -0.014307782 |
| Time                    | 5.64e+04     |
| Time-Optimization       | 5.48         |
| Time-SampleProc         | 0.142        |
| Time-Sampling           | 137          |
| n_timesteps             | 2860000      |
| train-AverageDiscoun... | -7.32        |
| train-AverageReturn     | -7.41        |
| train-EnvExecTime       | 8.4          |
| train-MaxReturn         | 9.65         |
| train-MinReturn         | -15.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 128          |
| train-StdReturn         | 5.61         |
------------------------------------------

 ---------------- Iteration 286 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 286          |
| ItrTime                 | 141          |
| LossAfter               | -0.012020309 |
| LossBefore              | -0.01881507  |
| Time                    | 5.66e+04     |
| Time-Optimization       | 8.04         |
| Time-SampleProc         | 0.0585       |
| Time-Sampling           | 132          |
| n_timesteps             | 2870000      |
| train-AverageDiscoun... | -6.49        |
| train-AverageReturn     | -2.42        |
| train-EnvExecTime       | 8.55         |
| train-MaxReturn         | 7.28         |
| train-MinReturn         | -11.1        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 123          |
| train-StdReturn         | 3.81         |
------------------------------------------

 ---------------- Iteration 287 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 287          |
| ItrTime                 | 142          |
| LossAfter               | 0.0075617647 |
| LossBefore              | 0.009149399  |
| Time                    | 5.67e+04     |
| Time-Optimization       | 6.56         |
| Time-SampleProc         | 0.0434       |
| Time-Sampling           | 135          |
| n_timesteps             | 2880000      |
| train-AverageDiscoun... | -11.7        |
| train-AverageReturn     | -4.49        |
| train-EnvExecTime       | 8.43         |
| train-MaxReturn         | 2.49         |
| train-MinReturn         | -11.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 126          |
| train-StdReturn         | 2.94         |
------------------------------------------

 ---------------- Iteration 288 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 288           |
| ItrTime                 | 137           |
| LossAfter               | -0.009372262  |
| LossBefore              | -0.0020892213 |
| Time                    | 5.68e+04      |
| Time-Optimization       | 5.74          |
| Time-SampleProc         | 0.0432        |
| Time-Sampling           | 131           |
| n_timesteps             | 2890000       |
| train-AverageDiscoun... | -10.8         |
| train-AverageReturn     | -3.95         |
| train-EnvExecTime       | 8.33          |
| train-MaxReturn         | 4.13          |
| train-MinReturn         | -11.6         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 122           |
| train-StdReturn         | 3.06          |
-------------------------------------------

 ---------------- Iteration 289 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 289         |
| ItrTime                 | 130         |
| LossAfter               | -0.02336319 |
| LossBefore              | 0.005264929 |
| Time                    | 5.7e+04     |
| Time-Optimization       | 6.09        |
| Time-SampleProc         | 0.0496      |
| Time-Sampling           | 124         |
| n_timesteps             | 2900000     |
| train-AverageDiscoun... | -4.45       |
| train-AverageReturn     | -2.11       |
| train-EnvExecTime       | 8.2         |
| train-MaxReturn         | 8.54        |
| train-MinReturn         | -11.3       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 115         |
| train-StdReturn         | 3.95        |
-----------------------------------------

 ---------------- Iteration 290 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 290         |
| ItrTime                 | 141         |
| LossAfter               | 0.01032738  |
| LossBefore              | 0.002944812 |
| Time                    | 5.71e+04    |
| Time-Optimization       | 5.4         |
| Time-SampleProc         | 0.0503      |
| Time-Sampling           | 136         |
| n_timesteps             | 2910000     |
| train-AverageDiscoun... | -13.6       |
| train-AverageReturn     | -10.4       |
| train-EnvExecTime       | 8.34        |
| train-MaxReturn         | 10.2        |
| train-MinReturn         | -15.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 127         |
| train-StdReturn         | 3.6         |
-----------------------------------------

 ---------------- Iteration 291 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 291          |
| ItrTime                 | 137          |
| LossAfter               | 0.0015013305 |
| LossBefore              | 0.0061384    |
| Time                    | 5.72e+04     |
| Time-Optimization       | 6.64         |
| Time-SampleProc         | 0.0616       |
| Time-Sampling           | 131          |
| n_timesteps             | 2920000      |
| train-AverageDiscoun... | -17.5        |
| train-AverageReturn     | -12.5        |
| train-EnvExecTime       | 8.54         |
| train-MaxReturn         | -8.59        |
| train-MinReturn         | -16.6        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 121          |
| train-StdReturn         | 1.75         |
------------------------------------------

 ---------------- Iteration 292 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 292          |
| ItrTime                 | 153          |
| LossAfter               | -0.008740097 |
| LossBefore              | -0.006401938 |
| Time                    | 5.74e+04     |
| Time-Optimization       | 5.58         |
| Time-SampleProc         | 0.0659       |
| Time-Sampling           | 147          |
| n_timesteps             | 2930000      |
| train-AverageDiscoun... | -18.2        |
| train-AverageReturn     | -12.9        |
| train-EnvExecTime       | 8.67         |
| train-MaxReturn         | -7.79        |
| train-MinReturn         | -17          |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 138          |
| train-StdReturn         | 1.8          |
------------------------------------------

 ---------------- Iteration 293 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 293          |
| ItrTime                 | 139          |
| LossAfter               | 0.0042307014 |
| LossBefore              | 0.0072360435 |
| Time                    | 5.75e+04     |
| Time-Optimization       | 5.05         |
| Time-SampleProc         | 0.06         |
| Time-Sampling           | 134          |
| n_timesteps             | 2940000      |
| train-AverageDiscoun... | -18.4        |
| train-AverageReturn     | -12.9        |
| train-EnvExecTime       | 8.53         |
| train-MaxReturn         | -8.77        |
| train-MinReturn         | -16.8        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 125          |
| train-StdReturn         | 1.73         |
------------------------------------------

 ---------------- Iteration 294 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 294           |
| ItrTime                 | 143           |
| LossAfter               | -0.010938544  |
| LossBefore              | -0.0071319398 |
| Time                    | 5.77e+04      |
| Time-Optimization       | 5.9           |
| Time-SampleProc         | 0.0561        |
| Time-Sampling           | 137           |
| n_timesteps             | 2950000       |
| train-AverageDiscoun... | -18.1         |
| train-AverageReturn     | -12.7         |
| train-EnvExecTime       | 8.74          |
| train-MaxReturn         | -8.78         |
| train-MinReturn         | -17.1         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 128           |
| train-StdReturn         | 1.71          |
-------------------------------------------

 ---------------- Iteration 295 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
------------------------------------------
| Itr                     | 295          |
| ItrTime                 | 142          |
| LossAfter               | -0.01560857  |
| LossBefore              | -0.016284352 |
| Time                    | 5.78e+04     |
| Time-Optimization       | 4.62         |
| Time-SampleProc         | 0.0474       |
| Time-Sampling           | 138          |
| n_timesteps             | 2960000      |
| train-AverageDiscoun... | -18.2        |
| train-AverageReturn     | -12.9        |
| train-EnvExecTime       | 8.45         |
| train-MaxReturn         | -8.28        |
| train-MinReturn         | -16.5        |
| train-NumTrajs          | 100          |
| train-PolicyExecTime    | 128          |
| train-StdReturn         | 1.65         |
------------------------------------------

 ---------------- Iteration 296 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 296         |
| ItrTime                 | 142         |
| LossAfter               | 0.016091006 |
| LossBefore              | 0.016886694 |
| Time                    | 5.8e+04     |
| Time-Optimization       | 4.93        |
| Time-SampleProc         | 0.0529      |
| Time-Sampling           | 137         |
| n_timesteps             | 2970000     |
| train-AverageDiscoun... | -17.5       |
| train-AverageReturn     | -12.6       |
| train-EnvExecTime       | 8.63        |
| train-MaxReturn         | -7.1        |
| train-MinReturn         | -16.6       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 127         |
| train-StdReturn         | 2.19        |
-----------------------------------------

 ---------------- Iteration 297 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 297         |
| ItrTime                 | 151         |
| LossAfter               | 0.008654217 |
| LossBefore              | 0.008882904 |
| Time                    | 5.81e+04    |
| Time-Optimization       | 8.17        |
| Time-SampleProc         | 0.19        |
| Time-Sampling           | 143         |
| n_timesteps             | 2980000     |
| train-AverageDiscoun... | -17.5       |
| train-AverageReturn     | -12.6       |
| train-EnvExecTime       | 8.84        |
| train-MaxReturn         | -8.95       |
| train-MinReturn         | -16.7       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 133         |
| train-StdReturn         | 1.8         |
-----------------------------------------

 ---------------- Iteration 298 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-------------------------------------------
| Itr                     | 298           |
| ItrTime                 | 230           |
| LossAfter               | -0.004214685  |
| LossBefore              | -0.0042204834 |
| Time                    | 5.83e+04      |
| Time-Optimization       | 6.37          |
| Time-SampleProc         | 0.134         |
| Time-Sampling           | 223           |
| n_timesteps             | 2990000       |
| train-AverageDiscoun... | -16.8         |
| train-AverageReturn     | -12.2         |
| train-EnvExecTime       | 11.5          |
| train-MaxReturn         | -3.25         |
| train-MinReturn         | -16.5         |
| train-NumTrajs          | 100           |
| train-PolicyExecTime    | 211           |
| train-StdReturn         | 2.3           |
-------------------------------------------

 ---------------- Iteration 299 ----------------
Sampling set of tasks/goals for this meta-batch...
Obtaining samples...
Processing samples...
Optimizing policy...
Saving snapshot...
Saved
-----------------------------------------
| Itr                     | 299         |
| ItrTime                 | 110         |
| LossAfter               | 0.015497028 |
| LossBefore              | 0.017081477 |
| Time                    | 5.85e+04    |
| Time-Optimization       | 4.59        |
| Time-SampleProc         | 0.0539      |
| Time-Sampling           | 106         |
| n_timesteps             | 3000000     |
| train-AverageDiscoun... | -14.3       |
| train-AverageReturn     | -10.8       |
| train-EnvExecTime       | 9.72        |
| train-MaxReturn         | 3.6         |
| train-MinReturn         | -15.2       |
| train-NumTrajs          | 100         |
| train-PolicyExecTime    | 95          |
| train-StdReturn         | 3.14        |
-----------------------------------------
Training finished
